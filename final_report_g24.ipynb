{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_report_G24 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/TheoNguyen611/d124ef67f2948ad8b6bf8aef40d66b3f/final_report_g24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-jhWFLvnkSW"
      },
      "source": [
        "#Project group 24 type 3 : CNN from scratch for CIPHAR 10\n",
        "___\n",
        "\n",
        "SZTEJNBERG Guillaume 300151080\n",
        "\n",
        "\n",
        "NGUYEN Théo 300151392\n",
        "\n",
        "\n",
        "SUAU Pierre-Nicolas 300150942"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjLk6zScgivc"
      },
      "source": [
        "<center><a href=\"https://zupimages.net/viewer.php?id=19/49/xcty.png\"><img src=\"https://zupimages.net/up/19/49/xcty.png\" alt=\"\" /></a></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYEOw7iX2sEV"
      },
      "source": [
        "# I)  Presentation of the project\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_okpabvXLVC"
      },
      "source": [
        "\n",
        "The first phase of our work was a documentary research. The main articles consulted are listed in annex. We needed to familiarize ourselves with the design details of convolutional neural networks.\n",
        "This first phase helped us define the architecture of our code. Our work would be divided in two major steps: the feature learning and the classification. The architecture of the code is simple: the network is composed of layers that perform forward computing and backward propagation. Backward propagation is essential to adjust the weights of the Neural network, in the Classification step and the filters in the Feature Learning step.\n",
        "\n",
        "<br> <center><a href=\"https://ibb.co/yVR1bF0\"><img src=\"https://i.ibb.co/V3NZPYV/Capture-d-e-cran-2019-12-04-a-17-42-38.png\" alt=\"Capture-d-e-cran-2019-12-04-a-17-42-38\" border=\"0\"></a></center> \n",
        "<center>model of our network (picture from toward science)</center><br>\n",
        "\n",
        "We first built the classification step of the convolutional network. We actually coded and tested a Neural network that would take in the features of images and return the classification of these images, among the ten classes of the data set. Our Neural network performed well with an accuracy reaching almost 50%.\n",
        "\n",
        "We then built the feature learning step. We decided to use one convolutional layer, followed by a reLu layer and a pooling layer. We first used known filters as the horizontal or vertical filter to test the good functioning of the layers (see pictures). Finally we computed random filters that would be corrected at each backward propagation to become efficient filters, corresponding to the used data set.\n",
        "\n",
        "<br> <center><a href=\"https://ibb.co/yVR1bF0\"><img src=\"https://zupimages.net/up/19/49/urr1.png\" alt=\"\" /></a></center> \n",
        "<center>Picture before and after horizontal filter (and convertion in black and white)</center><br>\n",
        "\n",
        "We then had to build a layer allowing to convert the feature maps obtained at the end of the feature learning step into information compatible with the Classification step. We therefore built a conversion layer that flattened all the feature maps corresponding to one picture, into a line of the entry matrix, taken in by the Classification step.\n",
        "\n",
        "Once our convolutional neural network was built we had to test it on Ciphar 10, our chosen data set. We were then confronted to the difficulty of the huge size of the dataset, so that we had to choose interesting parameters for the tests, knowing that each test was a few hours long. With these tests, we understood for instance that the learning rate played an important role in the learning process of the network. Accuracy grew much faster with a learning rate of 0,003 than 0,001.\n",
        "Finally to reduce the computing time of tests, we reduced our data set to only two possible classes (plane and horse). This allowed us to test different parameters more efficiently.\n",
        "\n",
        "# Annex:\n",
        "\n",
        "https://towardsdatascience.com/backpropagation-in-a-convolutional-layer-24c8d64d8509\n",
        "\n",
        "https://www.quora.com/How-do-we-compute-the-gradient-of-a-ReLU-for-backpropagation\n",
        "\n",
        "https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/\n",
        "\n",
        "https://datascience.stackexchange.com/questions/27506/back-propagation-in-cnn\n",
        "\n",
        "https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/\n",
        "\n",
        "https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
        "\n",
        "https://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html\n",
        "\n",
        "https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUgaXbrv3mAC"
      },
      "source": [
        "# III)  Presentation of the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSOjFnF64Pxb"
      },
      "source": [
        "Our dataset is CIPHAR10, it is one of the most famous dataset in machine learning. It is composed by 50000 pictures divided into 10 classes (dogs, trucks, airplanes…). Our goal is to be able de to predict the class that each picture belongs to. First, we did our tests with all classes but then we only took 2 of them. Obviously, the chosen features are pixels but we made a choice : we converted all pictures into black and white pictures in order to cut by 3 the size of pictures that go through convolution (the longest process of our algorithm).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A1j9H94O6cM"
      },
      "source": [
        "# II)  Main Code\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De07r_Phngng",
        "outputId": "f0b1f6a0-3733-4007-b492-37a22f298657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Execute to have all the toolkits used in the project\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "#tensorflow is used only to import the cifar 10 dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "import random \n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EidFPibwnvYE"
      },
      "source": [
        "Our model has the same architecture as tensorflow model. It means that there is one class for each kind of layer (convolution, pooling, relu...). Then there is a class for the model itself which is composed by all the layers that have been chosen.\n",
        "\n",
        "First, let's define the classes that will implement the CNN's layers. Each layer has two methods : backprop for the backprogration and compute for the forward propagation. Moreover, layers have specific attributes to store data(weight, input/output values...).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CG1_xNGPPha"
      },
      "source": [
        "###  1) Classification layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSJ-kGQRXjK"
      },
      "source": [
        "Our first task was to create  MLP layers  from scratch. Therefore, we found after a few searches, the formulas for the \"compute\" and the \"backprop\" functions here: https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
        "\n",
        "We adapted the code given for our own code. For example , the tutorial on the website computes the prop and the backprop with a bias, and we decided to ignore it at the begining to simplify the problem. Finally, the MLP part consists in a \"net layer\" (the linear part) and a \"relu layer \" (the non linear part) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVC9VTuWPfqZ"
      },
      "source": [
        "\"\"\" A generic class from which all the layers inherit.\"\"\"\n",
        "\n",
        "class generic_layer():\n",
        "\n",
        "  def __init__(self,features_size,output_size,example_size):\n",
        "\n",
        "    #Attributes (used only for the classification layers (Relu and  Net layer))\n",
        "\n",
        "    #It represents the ouptut of the layer ( for the the classification layer, the\n",
        "    #output is an example_size*output_size numpy array )\n",
        "    self.output=0\n",
        "    #Number of features as input of the layer \n",
        "    self.feature_nb=features_size\n",
        "    #Number of output (must match the number of features of the next layer)\n",
        "    self.output_nb=output_size\n",
        "    #Number of examples (basically the number of pictures in the batch)\n",
        "    self.example_nb=example_size\n",
        "    \n",
        "    \n",
        "  \"\"\"Computes the forward propagation for any type of layer \n",
        "  # Input : a batch of example (a list for the convolution layer and a matrix for \n",
        "    the neural network)\n",
        "  # Returns : list of features maps after convolution (output) and a \n",
        "    example_size*output_size numpy array in the classification layers\"\"\"\n",
        "\n",
        "  def compute(self):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  # It computes the backpropagation on all features maps.\n",
        "  # Input : the gradient of the next layer and the learning rate\n",
        "  # Returns : the gradient of the layer\n",
        "  def backprop(self,grad,learning_rate):\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" It extends the layer class to a layer with relu function for the convolution\n",
        "# step which aims to introduce a little bit of unlinearity by turning all negative \n",
        "#values to 0.\"\"\"\n",
        "\n",
        "class relu_layer_mlp(generic_layer):\n",
        "  # class constructor\n",
        "  def __init__(self,features_size,output_size,example_size):   \n",
        "    super().__init__(features_size,output_size,example_size)\n",
        "\n",
        "\n",
        "  \"\"\" It computes the forward propagation through the relu layer \n",
        "  #Input: none \n",
        "  #Returns: the output of the layer , example_size*output_size matrix\"\"\"\n",
        "  def compute(self):\n",
        "    # it takes the maximum of 0 and the coefficient for all coefficient in the \n",
        "    #matrix\n",
        "    output=np.maximum(0,self.input)\n",
        "    return(output)\n",
        "\n",
        "  \"\"\" It computes the forward propagation through the relu layer \n",
        "  #Input:none \n",
        "  #Returns: the output of the layer , example_size*output_size numpy array\"\"\"\n",
        "  def backprop(self,grad_output,learning_rate): \n",
        "    #a matrix of boolean (True if the coefficient of the input matrix is >0,\n",
        "    # else False)\n",
        "    relu_grad = self.input > 0\n",
        "    return grad_output*relu_grad \n",
        " \n",
        "\n",
        "\n",
        "\"\"\" extend the layer class to a layer with a net function, (linear part of the \n",
        "neuron) \"\"\"\n",
        "class net_layer(generic_layer):\n",
        "\n",
        "  #class constructor\n",
        "  def __init__(self,features_size,output_size,example_size):   \n",
        "    super().__init__(features_size,output_size,example_size)\n",
        "\n",
        "    #First nitialization of the weights on a normal  probability repartition \n",
        "    self.weights=np.random.normal(loc=0.0, \n",
        "                                        scale = np.sqrt(2/(features_size+output_size)), \n",
        "                                        size = (features_size,output_size))\n",
        "\n",
        "  \"\"\" It computes the forward propagation through the net layer \n",
        "  #Input: none \n",
        "  #Returns: the output of the layer , example_size*output_size matrix\"\"\"\n",
        "  def compute(self):\n",
        "\n",
        "    #check the dimensions of the matrix \n",
        "    \n",
        "    assert len(self.input[0])==self.feature_nb\n",
        "    \n",
        "\n",
        "   #It outputs the product of the input matrix with the weight matrix which\n",
        "   #is  equivalent to calculate the sum  input i*wi for each image example \n",
        "    output= np.dot(self.input,self.weights)\n",
        "   \n",
        "    return(output)\n",
        "\n",
        "  \"\"\" It computes the backward propagation through the net layer \n",
        "  #Input: gradient of the next layer (example_size) \n",
        "  #Returns: the output of the layer , example_size*output_size matrix\"\"\"\n",
        "  def backprop(self,grad_output,learning_rate):\n",
        "        \n",
        "        #grad input is the specific gradient of the layer \n",
        "        #which will be return to ompute the gradient of next (previous) layer\n",
        "   \n",
        "        grad_input = np.dot(grad_output, self.weights.T)\n",
        "        \n",
        "        #weight correction is a matrix (same shape as the weight matrix) whose \n",
        "        # coefficients are the derivative of the loss function with respect to\n",
        "        # the corresponding weight. \n",
        "        weights_correction = np.dot(self.input.T, grad_output)\n",
        "        \n",
        "        \n",
        "        # it corrects the weight with the correction matrix to perform gradient \n",
        "        #descent\n",
        "        self.weights = self.weights - learning_rate * weights_correction\n",
        "        \n",
        "        return grad_input \n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x6-ZDe_M25C"
      },
      "source": [
        "###  2)  feature learning  layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sma29ID6sSNd"
      },
      "source": [
        "In a second step we  defined the  layers for the features learning. The **main convolution layer** takes each picture of the batch and apply different filters to create a chosen number of activation map. To simplify the problem, and because the convolution layer requires a lot a CPU, we decided to work in black and white. **A relu layer** add some non-linearity and finally a **pooling layer** has been created. To connect the convolutional part with a classical fully connected layer in the first part, we had to code a **convert layer** to concatenate the different activation map of one picture and transform it into a row of features for the next layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZcaTYsUnuQD"
      },
      "source": [
        "\n",
        "\"\"\"It extends the layer class to a layer with convolution function.\"\"\"\n",
        "\n",
        "class convolution_layer(generic_layer):\n",
        "\n",
        "  def __init__(self,filters):\n",
        "\n",
        "    super().__init__(1,1,1)\n",
        "    self.filters=filters\n",
        "    self.pictures=0\n",
        "\n",
        "  \"\"\" It computes the convolution on a feature map.\n",
        "  # Input : the feature map (feature_map) that needs the convolution.\n",
        "  # Returns : the convoluated feature map (conv_im).\"\"\"\n",
        "\n",
        "  def convolution(self,filt,feature_map):\n",
        "\n",
        "    # It stores feature map's and filter's shapes.\n",
        "    map_row=feature_map.shape[0]\n",
        "    map_col=feature_map.shape[1]\n",
        "    filt_row=filt.shape[0]\n",
        "    filt_col=filt.shape[1]\n",
        "\n",
        "    # It initialises the convoluated feature map to zero.\n",
        "    conv_im= np.zeros([map_row-filt_row+1,map_col-filt_row+1])\n",
        "\n",
        "    for i in range(map_row-filt_row+1):\n",
        "\n",
        "      for j in range(map_col-filt_col+1):\n",
        "\n",
        "        # It computes and stores the convoluted feature map.\n",
        "        current_feature_map = feature_map[i:i+filt_row,j:j+filt_col].copy()\n",
        "        next_feature_map = (feature_map[i:i+filt_row,j:j+filt_col].copy())*filt\n",
        "        conv_im[i,j]=np.sum(next_feature_map)\n",
        "\n",
        "    return conv_im\n",
        "\n",
        "  \"\"\" It converts RGB pictures into Black and White pictures.\n",
        "  # Input : the list of RBG pictures.\n",
        "  # Output : the list of Black and White pictures.\"\"\"\n",
        "\n",
        "  def to_black_and_white(self, pictures):\n",
        "\n",
        "    # It creates the list of converted pictures.\n",
        "    conv_pictures=[]\n",
        "\n",
        "    for picture in pictures:\n",
        "\n",
        "      pic_row=picture.shape[0]\n",
        "      pic_col=picture.shape[1]\n",
        "      dim=picture.shape[2]\n",
        "\n",
        "      # It initiliases the future converted picture to zero.\n",
        "      conv_pic= np.zeros([pic_row,pic_col])\n",
        "\n",
        "      for i in range(pic_row):\n",
        "\n",
        "        for j in range(pic_col):\n",
        "\n",
        "          conv_pic[i,j]=1\n",
        "\n",
        "          for k in range(dim):\n",
        "\n",
        "            conv_pic[i,j] += -picture[i,j,k]/3\n",
        "      \n",
        "      #It stores the converted picture.\n",
        "      conv_pictures.append(conv_pic)\n",
        "\n",
        "    return np.array(conv_pictures)\n",
        "  \n",
        "  \"\"\"Computes the convolution.\n",
        "  # Input : Feature maps after convolution (self.input) and filters (self.filters).\n",
        "  # Returns : list of features maps after convolution (output).\"\"\"\n",
        "\n",
        "  def compute(self):\n",
        "\n",
        "    # It stores the filters.\n",
        "    filters=self.filters\n",
        "\n",
        "    # It converts pictures into black and white and then stores it.\n",
        "    self.pictures=self.to_black_and_white(self.input)\n",
        "\n",
        "    # It stores the numbers of pictures and filters.\n",
        "    nb_pictures = len(self.pictures)\n",
        "    nb_filters = len(filters)\n",
        "\n",
        "    # It stores the picture's shape.\n",
        "    nb_row_pic, nb_col_pic = self.convolution(filters[0],self.pictures[0]).shape\n",
        "\n",
        "    output = np.zeros([nb_pictures,nb_filters,nb_row_pic, nb_col_pic])\n",
        "\n",
        "    for i in range (nb_pictures):\n",
        "\n",
        "      for j in range (nb_filters):\n",
        "\n",
        "        # It computes the convolution of the current area of the picture.\n",
        "        output[i][j] = self.convolution(filters[j],self.pictures[i])\n",
        "    \n",
        "    return(output)\n",
        "\n",
        "  \"\"\" Computes the backpropagation for a single feature map.\n",
        "  # Input : filters (self.filters), the gradient of the next layer (output_gradient),\n",
        "   the input of the convolution layer (x), the number of the current filter (num_filt) \n",
        "   and the learning rate (learning_rate).\"\"\"\n",
        "\n",
        "  def backward(self,output_gradient,x,num_filter,learning_rate):\n",
        "\n",
        "    # It stores input's, gradient's of the next layer and filter's shapes.\n",
        "    x_row = x.shape[0]\n",
        "    x_col = x.shape[1]\n",
        "    y_row = output_gradient.shape[0]\n",
        "    y_col = output_gradient.shape[1]\n",
        "    w_row = self.filters[num_filter].shape[0]\n",
        "    w_col = self.filters[num_filter].shape[1]\n",
        "    \n",
        "    #It initialises the matrix which will sotre the weight correction.\n",
        "    delta_weight = np.zeros([w_row,w_col])\n",
        "\n",
        "    for row in range(w_row):\n",
        "\n",
        "      for col in range(w_col):\n",
        "\n",
        "        #delta_x[row+w_row,col+w_col] += self.filters[num_filter] * output_gradient[row,col]\n",
        "        #print(\"conv-->backward, shape x, row,col,w_row,w_col,output_gradient shape\",x.shape, row,col,w_row,w_col,output_gradient.shape)\n",
        "        # It computes the weight correction.\n",
        "        delta_weight[row,col] = np.sum(x[row:row+y_row,col:col+y_col] * output_gradient * learning_rate)\n",
        "\n",
        "    return delta_weight\n",
        "\n",
        "  \"\"\"Computes the backpropagation for all feature maps.\n",
        "  # Input : filters (self.filters), the black and white pictures (self.pictures), \n",
        "  the gradient of the next layer (grad), and the learning rate (learning_rate).\"\"\"\n",
        "\n",
        "  def backprop(self,grad,learning_rate):\n",
        "\n",
        "    # It stores the numbers of pictures and filters.\n",
        "    nb_pictures, nb_filters = len(self.pictures) , len(self.filters)\n",
        "\n",
        "    for num_im in range(nb_pictures):\n",
        "\n",
        "      for num_filter in range (nb_filters):\n",
        "\n",
        "        # It computes and stores backward propagation for the current feature map.\n",
        "        self.filters[num_filter] += self.backward(grad[num_im,num_filter],self.pictures[num_im],num_filter,learning_rate)\n",
        "\n",
        "\n",
        "\"\"\" It extends the layer class to a layer with relu function for the convolution \n",
        "step which aims to introduce a little bit of unlinearity by turning all negative \n",
        "values to 0.\"\"\"\n",
        "\n",
        "class relu_layer_conv(generic_layer):\n",
        "\n",
        "  def __init__(self,nb_pictures,nb_filters):\n",
        "\n",
        "    super().__init__(1,1,1)\n",
        "\n",
        "    self.nb_pictures = nb_pictures\n",
        "    self.nb_filters = nb_filters\n",
        "  \n",
        "  \"\"\"Computes the forward propagation.\n",
        "  # Input : Feature maps after convolution (self.input).\n",
        "  # Returns : Output : features mapts after relu, all negative values turned into\n",
        "   0, positive values go through.\"\"\"\n",
        "\n",
        "  def compute(self):\n",
        "    #print(\"conv-->relu input\",self.input)\n",
        "    nb_pictures, nb_filters, nb_row_image, nb_col_image = self.input.shape\n",
        "    output = np.zeros([nb_pictures, nb_filters, nb_row_image, nb_col_image])\n",
        "    for i in range(nb_pictures) :\n",
        "      for j in range(nb_filters) :\n",
        "        output[i,j] = np.maximum(0,self.input[i,j])\n",
        "\n",
        "    return(output)\n",
        "        \n",
        "  \"\"\"Computes the backward propagation.\n",
        "  # Input : Feature maps after convolution (self.input), gradient from the next layer \n",
        "  (grad_output) and the learning rate (learning_rate).\n",
        "  # Returns : Layer's gradient matrix (relu_grad), gradient values corresponding \n",
        "  to negative input values are turned into 0 and the ones corresponding to positive\n",
        "   values go through.\"\"\"\n",
        "\n",
        "  def backprop(self,grad_output,learning_rate): \n",
        "\n",
        "    nb_pictures, nb_filters, nb_row_image, nb_col_image = self.input.shape\n",
        "    relu_grad = np.zeros([nb_pictures, nb_filters, nb_row_image, nb_col_image])\n",
        "\n",
        "    for i in range(nb_pictures) :\n",
        "      for j in range(nb_filters) :\n",
        "        relu_grad[i,j] = (self.input[i,j] > 0)\n",
        "        relu_grad[i,j] = relu_grad[i,j]*grad_output[i,j]\n",
        "\n",
        "    return relu_grad \n",
        "\n",
        "\"\"\" It extends the layer class to a layer with pooling function which aims to select \n",
        "the most significative information \n",
        "by choosing the pixel with biggest value in a defined area.\"\"\"\n",
        "\n",
        "class pooling_layer (generic_layer):\n",
        "  def __init__(self,nb_pictures,nb_filters,filt_shape):\n",
        "    self.filt_shape=filt_shape\n",
        "    super().__init__(1,1,1)\n",
        "\n",
        "  \"\"\" It computes the pooling on a feature map.\n",
        "  # Input : the feature map (image) that needs to be pooled.\n",
        "  # Returns : the pooled feature map (next_feature), a matrix full of zeros \n",
        "  # except for the chosen pixels which are worth 1 (it will be useful for the backpropagation). \"\"\"\n",
        "\n",
        "  def pooling(self,image,stride=[1,1]):\n",
        "\n",
        "    # It stores map's and filter's shapes.\n",
        "    img_row = image.shape[0]\n",
        "    img_col = image.shape[1]\n",
        "    filt_row = self.filt_shape[0]\n",
        "    filt_col = self.filt_shape[1]\n",
        "    stride_row = stride[0]\n",
        "    stride_col = stride[1]\n",
        "\n",
        "    # It initialises the output feature map to zero with the appropriate shape.\n",
        "    next_feature = np.zeros([(img_row//filt_row),(img_col//filt_col)])\n",
        "\n",
        "    # It creates a list to store positions of chosen pixels.\n",
        "    positions = []\n",
        "\n",
        "    for i in range(0,img_row//filt_row+1,stride_row):\n",
        "\n",
        "      for j in range(0,img_col//filt_col+1,stride_col):\n",
        "\n",
        "        if (i+1)*filt_row <= img_row and (j+1)*filt_col <= img_col:\n",
        "\n",
        "          # It computes the next feature map value.\n",
        "          next_feature[i][j] = np.max(image[i*filt_row:(i+1)*filt_row,j*filt_col:(j+1)*filt_col])\n",
        "\n",
        "          # It computes the position of the chosen pixel (the one with the highest value).\n",
        "          pos = np.argmax(image[i*filt_row:(i+1)*filt_row,j*filt_col:(j+1)*filt_col], axis=None)\n",
        "          position=[0,0]\n",
        "          position[0] = pos//filt_row + i*filt_row\n",
        "          position[1] = pos%filt_col + j*filt_col\n",
        "          positions.append(position)\n",
        "\n",
        "    return next_feature,positions\n",
        "\n",
        "  \"\"\"\" It computes the pooling on all features maps.\n",
        "  # Input : The list composed by the feature maps (self.input).\n",
        "  # Returns : The liste composed by the pooled feature maps (output).\n",
        "  # It also stores the postion of each chosen pixel (self.positions_selected).\"\"\"\n",
        "\n",
        "  def compute(self):\n",
        "\n",
        "    # It stores features maps' and filter's shapes.\n",
        "    nb_pictures, nb_filters, nb_row_image, nb_col_image = self.input.shape\n",
        "    self.positions_selected = np.zeros([nb_pictures, nb_filters, nb_row_image, nb_col_image])\n",
        "\n",
        "    # It stores output's shape.\n",
        "    next_nb_row_image,next_nb_col_image = self.pooling(self.input[0,0])[0].shape\n",
        "    \n",
        "    # It initialises output to zero.\n",
        "    output= np.zeros([nb_pictures, nb_filters,next_nb_row_image,next_nb_col_image])\n",
        "\n",
        "\n",
        "    for i in range(nb_pictures):\n",
        "\n",
        "      for j in range(nb_filters):\n",
        "\n",
        "        # It computes the pooled feature maps of the jth feature map of the ith picture.\n",
        "        output[i,j]=self.pooling(self.input[i,j])[0]\n",
        "        positions=self.pooling(self.input[i,j])[1]\n",
        "\n",
        "        for pos in positions:\n",
        "\n",
        "          self.positions_selected[i,j,pos[0],pos[1]]=1\n",
        "\n",
        "    return (output)\n",
        "\n",
        "\n",
        "  \"\"\"It computes the backpropagation on all features maps.\n",
        "  # Input : Feature maps after relu (self.input), postions of all the chosen pixels \n",
        "    (self.positions_selected) gradient from the next layer (grad_output) and the \n",
        "    learning rate (learning_rate).\n",
        "  # Returns : The list composed by Layer's gradient matrix (pool_grad), gradient \n",
        "    values corresponding to unchosen pixels into 0 \n",
        "    and the ones corresponding to chosen pixels go through.\"\"\"\n",
        "\n",
        "\n",
        "  def backprop(self,grad_output,learning_rate):\n",
        "\n",
        "    # It stores the numbers of feature maps and filters.\n",
        "    nb_pictures, nb_filters, nb_row_image, nb_col_image = self.positions_selected.shape\n",
        "\n",
        "    # It stores next feature maps' shape.\n",
        "    nb_row_output, nb_col_output = grad_output[0,0].shape\n",
        "\n",
        "    # It stores the filters' shape.\n",
        "    nb_row_filt, nb_col_filt = nb_row_image//nb_row_output,nb_col_image//nb_col_output\n",
        "\n",
        "    # It initialises the gradient matrix.\n",
        "    pool_grad = self.positions_selected.copy()\n",
        "\n",
        "    for i in range(nb_pictures):\n",
        "\n",
        "      for j in range(nb_filters):\n",
        "\n",
        "        for k in range(nb_row_output):\n",
        "\n",
        "          for l in range(nb_col_output):\n",
        "\n",
        "            pool_grad[i,j,k*nb_row_filt:(k+1)*nb_row_filt,l*nb_col_filt:(l+1)*nb_col_filt] = self.positions_selected[i,j,k*nb_row_filt:(k+1)*nb_row_filt,l*nb_col_filt:(l+1)*nb_col_filt] * grad_output[i,j,k,l]\n",
        "\n",
        "    return pool_grad\n",
        " \n",
        "\n",
        "\n",
        "#extend the layer class to a layer with a conversion function from\n",
        "#the feature learning step to the classification step\n",
        "class convert_layer(generic_layer):\n",
        "    \n",
        "    def __init__(self):   \n",
        "        super().__init__(1,1,1)\n",
        "        \n",
        "    def compute(self):\n",
        "        output=[]\n",
        "        #list_matrix contains all the features maps associated to one image. \n",
        "        #There are as many feature_maps as the number of filters used in the feature learning step\n",
        "        for list_matrix in self.input:\n",
        "            #list_features will contain the features from all the feature_maps\n",
        "            #associated to one image from the batch\n",
        "            list_features=[]\n",
        "            #we go through every pixel of every feature_map and add it to list_features\n",
        "            for matrix in list_matrix:\n",
        "\n",
        "                for line in matrix:\n",
        "\n",
        "                    for value in line:\n",
        "\n",
        "                        list_features.append(value)\n",
        "            #Finally each line of features (list_feature) corresponding to one \n",
        "            #image of the batch is added to output.\n",
        "            output.append(list_features)\n",
        "        \n",
        "        return np.asarray(output)\n",
        "    \n",
        "    \"\"\" Computes the backward propagation.\n",
        "    # Input : Feature maps after feature learning step (self.input), gradient from the next layer (grad_output).\n",
        "    # Returns : Layer's gradient matrix, here the input gradient values will match the output gradient values.\n",
        "    #          Only the shape of the storage is changing.\"\"\"\n",
        "    def backprop(self,grad_output,learning_rate):\n",
        "      #first we get the shape of the input of the layer. The output gradient will have the same shape.\n",
        "        #It computes how many lines a feature_map contains\n",
        "        length_matrix=len(self.input[0][0])\n",
        "        #It computes how long is one of these lines.\n",
        "        length_line_matrix=len(self.input[0][0][0])\n",
        "        #grad_input will contain the gradient of the feature_maps associated to each image of the batch\n",
        "        grad_input=[]\n",
        "        #list_grad_features contain the gradient of all the features associated to one image.\n",
        "        for list_grad_features in grad_output:\n",
        "            #list_grad_matrix will contain all the gradient matrices associated to one image.\n",
        "            list_grad_matrix=[]\n",
        "            l=list(list_grad_features.copy())\n",
        "            #Here we go through one line of the output gradient and pop the values\n",
        "            #into the right matrix into list_grad matrix.\n",
        "            while l!=[]:\n",
        "\n",
        "                count_matrix=0\n",
        "                matrix=[]\n",
        "\n",
        "                while count_matrix<length_matrix:\n",
        "\n",
        "                    line_count=0\n",
        "                    line_grad=[]\n",
        "\n",
        "                    while line_count<length_line_matrix:\n",
        "\n",
        "                        line_grad.append(l.pop(0))\n",
        "                        line_count+=1\n",
        "\n",
        "                    matrix.append(line_grad)\n",
        "                    count_matrix+=1\n",
        "\n",
        "                list_grad_matrix.append(matrix)\n",
        "            #When list_grad_matrix contains all the gradients associated to one image, \n",
        "            #it is added to grad_input.\n",
        "            grad_input.append(list_grad_matrix)\n",
        "        \n",
        "        return np.asarray(grad_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAB-OFaygK96"
      },
      "source": [
        "# 2) Model definition\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CujmQphv-yLY"
      },
      "source": [
        "Here is the class that we implemented for the model. It contains the main classes for forward and backward propagation, but also the functions to compute the  crossentropy gradient and the acccuracy, the recall, and the precision. \n",
        "For the loss function, we tried first the  classical crossentropy described here: https://deepnotes.io/softmax-crossentropy\n",
        "However, the function was not stable enough ( we got \"nan\" and \"overflow\" at the output of the network). That is why we tried another loss function, the log softmax, which has a better numerical stability according to the website:  https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rbq2zEne5yc"
      },
      "source": [
        "\"\"\"General class which represents a configurable CNN model and contains all necessary \n",
        "attributes and method to train and predict with a batch of example\"\"\"\n",
        "class model(): \n",
        "  #constructor\n",
        "  def __init__(self,learning_rate,model_type):\n",
        "\n",
        "    #list of all the layer in a correct order\n",
        "    self.layers=[]\n",
        "\n",
        "    #model type is an attribute to know if we test the model with or without convolutional \n",
        "    #layer. It is basically useful to know it in the \"creat_input\" method\n",
        "    assert ((model_type==\"MLP\") or (model_type==\"CNN\")),\"Choose a valid model type\"\n",
        "    self.model_type=model_type\n",
        "\n",
        "    self.output=None\n",
        "    #current grad stored during the main backpropagagtion. It may have several forms \n",
        "    #depending on the class of the current layer\n",
        "    self.grad=None\n",
        "\n",
        "    #learning rate of the model \n",
        "    self.learning_rate=learning_rate\n",
        "\n",
        "    #number of correct match found. This attribute is updated during the training \n",
        "    # It has to be set to 0 before a prediction and at each epoch\n",
        "    self.correct_match=0\n",
        "    \n",
        "  \n",
        "  \"\"\"Function to add a layer to the model\n",
        "  #input: a layer of any class\n",
        "  #output: none\"\"\"\n",
        "  def add_layer(self,layer):\n",
        "    self.layers.append(layer)\n",
        "  \n",
        "  \"\"\"Main function to propagate the batch in input through the CNN.\n",
        "  #input: train_data is a batch of pictures if the first layer is a convolution, \n",
        "  a matrix of flatten pictures if the first layer is a net layer\n",
        "  #output: none\"\"\"\n",
        "  def propagate(self,train_data):\n",
        "\n",
        "    input=train_data\n",
        "    #for each layer, it goes through the \"compute function\"\n",
        "    for layer in self.layers:\n",
        "      #set the input of the layer\n",
        "      layer.input=np.copy(input)\n",
        "\n",
        "      #compute the output\n",
        "      layer.output=layer.compute()\n",
        "      \n",
        "      #the output of the layer becomes the input of the next layer\n",
        "      input=np.copy(layer.output)\n",
        "     \n",
        "\n",
        "  \"\"\" Main function to propagate backward the gradient in  order to update the weights \n",
        "  for the gradient descent.\n",
        "  #input: none\n",
        "  #output: none\"\"\"\n",
        "  def main_backprop(self):\n",
        "    \n",
        "    # for each layer in a reverse order, calls, the backprop function \n",
        "    # which compute the new gradient for the chain rule or/and update weights\n",
        "    #if the layer has weights\n",
        "    for i in range(len(self.layers))[::-1]:\n",
        "      self.grad=self.layers[i].backprop(self.grad,self.learning_rate)\n",
        "      \n",
        "      \n",
        "  \"\"\"It  computes the accuracy after a forward propagation\n",
        "  #input: the labels of the batch  that went through the network\n",
        "  #Returns: none\"\"\"\n",
        "  def accuracy_count(self,batch_labels):\n",
        "\n",
        "    #get the output of the network as prediction\n",
        "    prediction=self.layers[-1].output\n",
        "\n",
        "    #select for each picture of the batch , the class which has the highest \n",
        "    #coefficient in the output. Create a vector max_index with those coefficients\n",
        "    max_index=np.argmax(prediction,axis=1)\n",
        "\n",
        "    #for each example check if there is a match and update the count\n",
        "    batch_match=0\n",
        "    for i in range(len(max_index)):\n",
        "      if max_index[i]==int(batch_labels[i]):\n",
        "        batch_match+=1\n",
        "    #add the number of match for this batch to the total amount of match during \n",
        "    #an epoch\n",
        "    self.correct_match+=batch_match\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"It forecast on a test vector with the current state of the model\n",
        "  #Input: test data is a vector of pictures, test label is a vector with the label \n",
        "  of each picture\n",
        "  #Returns: the accuracy on the test vector, a list of the precision for all classes, \n",
        "  a list of the recall for all classes\"\"\"\n",
        "  def prediction(self,test_data,test_label,class_number):\n",
        "    #print(\"\\n---prediction:\")\n",
        "    self.propagate(test_data)\n",
        "    #reset the number of match\n",
        "    self.correct_match=0\n",
        "    #update the number of match on the test vector\n",
        "    self.accuracy_count(test_label)\n",
        "    accuracy=self.correct_match/len(test_label)\n",
        "\n",
        "\n",
        "    precision_list=[]\n",
        "    recall_list=[]\n",
        "    for class_i in range(class_number):\n",
        "      precision,recall=self.precision_and_recall(test_data,test_label,class_i)\n",
        "      precision_list.append(precision)\n",
        "      recall_list.append(recall)\n",
        "\n",
        "    print(\" \\n\\n precisions for all classes: \"+str(precision_list))\n",
        "    print(\"  recall for all classes:\"+str(recall_list))\n",
        "    print(\"  Accuracy\"+str(accuracy))\n",
        "    return(accuracy,precision_list,recall_list)\n",
        "\n",
        "\n",
        "  \n",
        "  \"\"\" Function to compute precision and recall for a particular class\n",
        "  #Input: test data is a vector of pictures, test label is a vector with the label \n",
        "  of each picture, class_number is the class on which we want to compute the recall and\n",
        "  the precision \n",
        "  #Returns: the precision and the recall of the class\"\"\"\n",
        "  def precision_and_recall(self,test_data,test_label,class_number_i):\n",
        "   \n",
        "    #initializes indicators\n",
        "\n",
        "    correct_match_class_i=0 #number of True Positive\n",
        "    predicted_as_i=0 #number of \n",
        "    number_of_element_i=0\n",
        "    #update the number of match on the test vector\n",
        "    #get the output of the network as prediction\n",
        "    prediction=self.layers[-1].output\n",
        "\n",
        "    #select for each picture of the batch , the class which has the highest \n",
        "    #coefficient in the output. Create a vector max_index with those coefficients\n",
        "    max_index=np.argmax(prediction,axis=1)\n",
        "    #print(\"max_index: \", max_index)\n",
        "\n",
        "    \n",
        "    for j in range(len(max_index)):\n",
        "      if max_index[j]==class_number_i:\n",
        "        predicted_as_i+=1\n",
        "        if max_index[j]==int(test_label[j]):\n",
        "          correct_match_class_i+=1\n",
        "      if int(test_label[j])==class_number_i:\n",
        "        number_of_element_i+=1\n",
        "    if(predicted_as_i==0 or number_of_element_i==0):\n",
        "      precision,recall=0,0\n",
        "    else:\n",
        "      precision=correct_match_class_i/predicted_as_i\n",
        "      recall=correct_match_class_i/number_of_element_i\n",
        "    print(\"  Class: \"+ str(class_number_i) +\" Correct match:\"+ str(correct_match_class_i)\n",
        "    +\" Number of elements:\"+ str(number_of_element_i)+\" Forecast as i:\"+  str(predicted_as_i))\n",
        "    \n",
        "    return(precision,recall)\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\" Main function to train the model. It executes a forward propagation,\n",
        "  computes the crossentropy and executes a backward propagation to update weights\n",
        "  #Input:train_batch is a batch of pictures if the first layer is a convolution, \n",
        "  a matrix of flatten pictures if the first layer is a net layer. train_label is\n",
        "  a vector of the corresponding labels\n",
        "  #Returns: the accuracy on the test vector\"\"\"\n",
        "  def fit(self,train_batch,train_label):\n",
        "\n",
        "    #first propagation in the network\n",
        "    self.propagate(train_batch)\n",
        "    #update the number of match\n",
        "    self.accuracy_count(train_label)\n",
        "    \n",
        "    #backpropagation in the network to update weights\n",
        "    self.grad=self.grad_crossentropy(self.layers[-1].output,train_label)\n",
        "    \n",
        "    self.main_backprop()\n",
        "    \n",
        "  \"\"\" This function computes the gradient of the crossentropy after a forward propagation\n",
        "  #Input: network_outptut is the output of the last layer (prediction), \n",
        "  reference_answers is a vector with the number of each picture's class\n",
        "  #Returns: an matrix example_size*output_size where each coeeficient represents the derivative \n",
        "  of the crossentropy with respect to the corresponding ouptut for the corresponding \n",
        "  picture of the batch\n",
        "  code adapted from: https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
        "  \"\"\"\n",
        "  def grad_crossentropy(self,layer_output,reference_answers):\n",
        "    \n",
        "    #ones_for_answers is a matrix where a coefficient aij is equal to \n",
        "    #one if the neural network forecast that the ith example is of class j\n",
        "    ones_for_answers = np.zeros_like(layer_output)\n",
        "    ones_for_answers[np.arange(len(layer_output)),reference_answers.astype(int)] = 1\n",
        "    \n",
        "    #compute the softmax function\n",
        "    softmax = np.exp(layer_output) / np.exp(layer_output).sum(axis=-1,keepdims=True)\n",
        "    #return the gradient of the softmax\n",
        "    return (- ones_for_answers + softmax) / layer_output.shape[0]\n",
        "  \n",
        "   \n",
        "  \n",
        "  \"\"\" This function creates mini batches of the desired size to feed the model. \n",
        "  The set of mini-batches covers all the given train datas. The order to pick the \n",
        "  pictures from the train set is random.\n",
        "  #Input: \"images\" is an array of pictures (number of samples x 32x32x3), \"labels\" \n",
        "  a vector with the labels,  \"batch_size\" is the number of sample by batch, \"shuffle\"\n",
        "  is a boolean which is True if we want to suffle simultaneously the images and their\n",
        "  labels.\n",
        "  #Returns: a list of batch and a list with the labels of each batch in the same order \n",
        "  If the model is a CNN, then a batch is an array of picture, if the model is \n",
        "  a MLP, a batch is a matrix of size number of batch x 3\"\"\"\n",
        "\n",
        "  def create_input(self,images, labels, batch_size,shuffle):\n",
        "    #get the length of the train data\n",
        "    len_data=len(images)\n",
        "    #If the batch size doesn't divide the number of pictures, we parse less images \n",
        "    len_data_parsed=len_data-(len_data%batch_size)\n",
        "\n",
        "    #count the total number of pixel in an image to get the exact feature number\n",
        "    #if the model is an MLP\n",
        "    feature_nb=1\n",
        "    for i in images[0].shape:\n",
        "      feature_nb=feature_nb*i\n",
        "\n",
        "\n",
        "    if shuffle:\n",
        "      #create a list of index to permute the images in the parsed datas. \n",
        "      index_list=random.sample(range(len(images)),len_data_parsed)\n",
        "    else: \n",
        "      index_list=range(len_data_parsed)\n",
        "\n",
        "    #create an empty batch with correct dimensions\n",
        "    batch=None\n",
        "    if(self.model_type==\"MLP\"):\n",
        "      batch=np.zeros((batch_size,feature_nb))\n",
        "    if(self.model_type==\"CNN\"):\n",
        "      batch=np.empty((batch_size,)+images[0].shape)\n",
        "    \n",
        "    #create an empty batch_label array with the correct dimensions\n",
        "    batch_label=np.zeros(batch_size)\n",
        "\n",
        "\n",
        "    batch_label_list=[]\n",
        "    batch_list=[]\n",
        "    row=0\n",
        "\n",
        "    #Following the shuffled index list, pick the number of images wanted to form \n",
        "    #the first batch, and so on... \n",
        "    for i in index_list:\n",
        "\n",
        "      #in the case of a MLP, an image is flatten into features\n",
        "      if(self.model_type==\"MLP\"):\n",
        "        batch[row][:]=images[i].flatten()\n",
        "        \n",
        "      #in the case of a CNN , the input is directly a batch of image\n",
        "      if(self.model_type==\"CNN\"):\n",
        "        batch[row]=images[i]\n",
        "\n",
        "      #the labels are also organized in batches\n",
        "      batch_label[row]=labels[i]  \n",
        "      row+=1\n",
        "\n",
        "      #eachh time  the batch is full, go to the next batch\n",
        "      if row==batch_size:\n",
        "        curr_batch=np.copy(batch)\n",
        "        curr_label=np.copy(batch_label)\n",
        "        batch_list.append(curr_batch)\n",
        "        batch_label_list.append(curr_label)\n",
        "        row=0\n",
        "    \n",
        "    return(batch_list,batch_label_list)\n",
        "\n",
        "\n",
        "   \n",
        "  \"\"\" This function initializes the filters of the convolution layer with random numbers\n",
        "  #input: The number of filters and their size\n",
        "  #returns: a list with all the filters initialized\"\"\"\n",
        "  def create_filters(self,nb_filters, size_filter):\n",
        "    list_filters=[]\n",
        "    for i in range(nb_filters):\n",
        "        filter=np.zeros((size_filter, size_filter))\n",
        "        for j in range(size_filter):\n",
        "            for k in range(size_filter):\n",
        "                filter[j][k]=random.random()\n",
        "        list_filters.append(filter)\n",
        "    return list_filters\n",
        "\n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utpyg6gzy4hd"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGCegymgfuJR"
      },
      "source": [
        "# IV) Model testing on CIFAR 10 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WWr3t45GvV1"
      },
      "source": [
        "\n",
        "We need first to download  and normalize the data set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpzpeebOuBVU",
        "outputId": "01f68036-c55d-4763-f64d-93d1d17e75f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "import random \n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1k_4VI3fmem"
      },
      "source": [
        "## 1) Test of the Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMBFuCPqtCk6"
      },
      "source": [
        "We tested first the model as MLP ( only fully connected layers). Here is a model with the optimal parameters that we found after a few searches. As you can see,  we reach sometimes 30% of accuracy after 10 epochs, which is not bad, considering that the images are flatten, so features are not processed at the input. \n",
        "When analyzing the results further, we can see that over epochs, some classes have zero match! It means that the MLP fails on some classes that it is not able to identify, maybe because of the lack of feature processing. That is why the accruacy is low, while precision/recall on some classes are not bad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnf_2r4np9Kn",
        "outputId": "db838a3c-6a1c-4feb-ad97-20cd6b0ed668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\"\"\"Test of the  MLP \"\"\"\n",
        "np.random.seed(42)\n",
        "\n",
        "#define the model with an appropriate learning rate and 5 layers\n",
        "Network=model(0.1,\"MLP\")\n",
        "layer1=net_layer(3072,100,10)\n",
        "layer2=relu_layer_mlp(100,100,10)\n",
        "layer3=net_layer(100,10,10)\n",
        "layer4=relu_layer_mlp(10,10,10)\n",
        "layer5=net_layer(10,10,10)\n",
        "\n",
        "Network.add_layer(layer1)\n",
        "Network.add_layer(layer2)\n",
        "Network.add_layer(layer3)\n",
        "Network.add_layer(layer4)\n",
        "Network.add_layer(layer5)\n",
        "\n",
        "\n",
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "\n",
        "#creates a huge batch with all the test data (for the prediction)\n",
        "test_list,test_labels_list=Network.create_input(test_images, test_labels, len(test_labels),False)\n",
        "\n",
        "#Iterate over the epocs\n",
        "for epoch in range (10):\n",
        "  print(\"\\n-------------- Epoch:\"+str(epoch)+\"--------------\\n\")\n",
        "  #create a new batch list at each epoch\n",
        "  batch_list,batch_labels_list=Network.create_input(train_images, train_labels, 10,False)\n",
        "  #train the network for each batch\n",
        "  for b,l in zip(batch_list,batch_labels_list):\n",
        "    Network.fit(b,l)\n",
        "  #Compute the accuracy on train set\n",
        "  train_accuracy=Network.correct_match/len(train_labels)\n",
        "  train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "  #Compute the accuracy, precision, recall  on test set\n",
        "  Network.correct_match=0\n",
        "  test_accuracy,precision,recall=Network.prediction(test_list[0],test_labels_list[0],10)\n",
        "  test_accuracy_list.append(test_accuracy)\n",
        "  print(\"ACCURACY ON TEST SET: \", test_accuracy)\n",
        "  print(\"ACCURACY ON TRAIN SET \", train_accuracy)\n",
        "  \n",
        "#plot the results\n",
        "plt.plot(range(10),test_accuracy_list,label=\"test_accuracy\")\n",
        "plt.plot(range(10),train_accuracy_list,label=\"train_accuracy\")\n",
        "plt.legend(loc='best')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------- Epoch:0--------------\n",
            "\n",
            "  Class: 0 Correct match:148 Number of elements:1000 Forecast as i:1461\n",
            "  Class: 1 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:3 Number of elements:1000 Forecast as i:21\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:970 Number of elements:1000 Forecast as i:8518\n",
            "  Class: 6 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 8 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 9 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            " \n",
            "\n",
            " precisions for all classes: [0.10130047912388775, 0, 0, 0.14285714285714285, 0, 0.11387649683024184, 0, 0, 0, 0]\n",
            "  recall for all classes:[0.148, 0, 0, 0.003, 0, 0.97, 0, 0, 0, 0]\n",
            "  Accuracy0.1121\n",
            "ACCURACY ON TEST SET:  0.1121\n",
            "ACCURACY ON TRAIN SET  0.1024\n",
            "\n",
            "-------------- Epoch:1--------------\n",
            "\n",
            "  Class: 0 Correct match:6 Number of elements:1000 Forecast as i:80\n",
            "  Class: 1 Correct match:4 Number of elements:1000 Forecast as i:5\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 4 Correct match:160 Number of elements:1000 Forecast as i:2430\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:841 Number of elements:1000 Forecast as i:4697\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 8 Correct match:622 Number of elements:1000 Forecast as i:2520\n",
            "  Class: 9 Correct match:45 Number of elements:1000 Forecast as i:268\n",
            " \n",
            "\n",
            " precisions for all classes: [0.075, 0.8, 0, 0, 0.06584362139917696, 0, 0.17905045773898232, 0, 0.24682539682539684, 0.16791044776119404]\n",
            "  recall for all classes:[0.006, 0.004, 0, 0, 0.16, 0, 0.841, 0, 0.622, 0.045]\n",
            "  Accuracy0.1678\n",
            "ACCURACY ON TEST SET:  0.1678\n",
            "ACCURACY ON TRAIN SET  0.18666\n",
            "\n",
            "-------------- Epoch:2--------------\n",
            "\n",
            "  Class: 0 Correct match:866 Number of elements:1000 Forecast as i:7216\n",
            "  Class: 1 Correct match:596 Number of elements:1000 Forecast as i:1933\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:3 Number of elements:1000 Forecast as i:22\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:174 Number of elements:1000 Forecast as i:638\n",
            "  Class: 6 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 8 Correct match:37 Number of elements:1000 Forecast as i:119\n",
            "  Class: 9 Correct match:8 Number of elements:1000 Forecast as i:72\n",
            " \n",
            "\n",
            " precisions for all classes: [0.12001108647450111, 0.3083290222452147, 0, 0.13636363636363635, 0, 0.2727272727272727, 0, 0, 0.31092436974789917, 0.1111111111111111]\n",
            "  recall for all classes:[0.866, 0.596, 0, 0.003, 0, 0.174, 0, 0, 0.037, 0.008]\n",
            "  Accuracy0.1684\n",
            "ACCURACY ON TEST SET:  0.1684\n",
            "ACCURACY ON TRAIN SET  0.22074\n",
            "\n",
            "-------------- Epoch:3--------------\n",
            "\n",
            "  Class: 0 Correct match:240 Number of elements:1000 Forecast as i:1972\n",
            "  Class: 1 Correct match:725 Number of elements:1000 Forecast as i:2565\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:843 Number of elements:1000 Forecast as i:4687\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 8 Correct match:218 Number of elements:1000 Forecast as i:776\n",
            "  Class: 9 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            " \n",
            "\n",
            " precisions for all classes: [0.12170385395537525, 0.2826510721247563, 0, 0, 0, 0, 0.17985918497973116, 0, 0.2809278350515464, 0]\n",
            "  recall for all classes:[0.24, 0.725, 0, 0, 0, 0, 0.843, 0, 0.218, 0]\n",
            "  Accuracy0.2026\n",
            "ACCURACY ON TEST SET:  0.2026\n",
            "ACCURACY ON TRAIN SET  0.23328\n",
            "\n",
            "-------------- Epoch:4--------------\n",
            "\n",
            "  Class: 0 Correct match:72 Number of elements:1000 Forecast as i:627\n",
            "  Class: 1 Correct match:820 Number of elements:1000 Forecast as i:3070\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:1\n",
            "  Class: 3 Correct match:4 Number of elements:1000 Forecast as i:30\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:872 Number of elements:1000 Forecast as i:5213\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:1\n",
            "  Class: 8 Correct match:328 Number of elements:1000 Forecast as i:1025\n",
            "  Class: 9 Correct match:2 Number of elements:1000 Forecast as i:33\n",
            " \n",
            "\n",
            " precisions for all classes: [0.11483253588516747, 0.2671009771986971, 0.0, 0.13333333333333333, 0, 0, 0.16727412238634184, 0.0, 0.32, 0.06060606060606061]\n",
            "  recall for all classes:[0.072, 0.82, 0.0, 0.004, 0, 0, 0.872, 0.0, 0.328, 0.002]\n",
            "  Accuracy0.2098\n",
            "ACCURACY ON TEST SET:  0.2098\n",
            "ACCURACY ON TRAIN SET  0.23528\n",
            "\n",
            "-------------- Epoch:5--------------\n",
            "\n",
            "  Class: 0 Correct match:67 Number of elements:1000 Forecast as i:1545\n",
            "  Class: 1 Correct match:891 Number of elements:1000 Forecast as i:3956\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:2\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:678 Number of elements:1000 Forecast as i:3714\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:1\n",
            "  Class: 8 Correct match:212 Number of elements:1000 Forecast as i:782\n",
            "  Class: 9 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            " \n",
            "\n",
            " precisions for all classes: [0.04336569579288026, 0.22522750252780585, 0, 0.0, 0, 0, 0.1825525040387722, 0.0, 0.2710997442455243, 0]\n",
            "  recall for all classes:[0.067, 0.891, 0, 0.0, 0, 0, 0.678, 0.0, 0.212, 0]\n",
            "  Accuracy0.1848\n",
            "ACCURACY ON TEST SET:  0.1848\n",
            "ACCURACY ON TRAIN SET  0.2472\n",
            "\n",
            "-------------- Epoch:6--------------\n",
            "\n",
            "  Class: 0 Correct match:394 Number of elements:1000 Forecast as i:2027\n",
            "  Class: 1 Correct match:855 Number of elements:1000 Forecast as i:3371\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:760 Number of elements:1000 Forecast as i:4370\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 8 Correct match:104 Number of elements:1000 Forecast as i:227\n",
            "  Class: 9 Correct match:0 Number of elements:1000 Forecast as i:5\n",
            " \n",
            "\n",
            " precisions for all classes: [0.1943759250123335, 0.2536339365173539, 0, 0, 0, 0, 0.17391304347826086, 0, 0.4581497797356828, 0.0]\n",
            "  recall for all classes:[0.394, 0.855, 0, 0, 0, 0, 0.76, 0, 0.104, 0.0]\n",
            "  Accuracy0.2113\n",
            "ACCURACY ON TEST SET:  0.2113\n",
            "ACCURACY ON TRAIN SET  0.2477\n",
            "\n",
            "-------------- Epoch:7--------------\n",
            "\n",
            "  Class: 0 Correct match:533 Number of elements:1000 Forecast as i:2852\n",
            "  Class: 1 Correct match:827 Number of elements:1000 Forecast as i:2758\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:706 Number of elements:1000 Forecast as i:4176\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:1\n",
            "  Class: 8 Correct match:89 Number of elements:1000 Forecast as i:177\n",
            "  Class: 9 Correct match:5 Number of elements:1000 Forecast as i:36\n",
            " \n",
            "\n",
            " precisions for all classes: [0.18688639551192146, 0.2998549673676577, 0, 0, 0, 0, 0.16906130268199235, 0.0, 0.5028248587570622, 0.1388888888888889]\n",
            "  recall for all classes:[0.533, 0.827, 0, 0, 0, 0, 0.706, 0.0, 0.089, 0.005]\n",
            "  Accuracy0.216\n",
            "ACCURACY ON TEST SET:  0.216\n",
            "ACCURACY ON TRAIN SET  0.22198\n",
            "\n",
            "-------------- Epoch:8--------------\n",
            "\n",
            "  Class: 0 Correct match:158 Number of elements:1000 Forecast as i:2149\n",
            "  Class: 1 Correct match:871 Number of elements:1000 Forecast as i:3496\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:6\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:2\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:641 Number of elements:1000 Forecast as i:3660\n",
            "  Class: 7 Correct match:2 Number of elements:1000 Forecast as i:9\n",
            "  Class: 8 Correct match:223 Number of elements:1000 Forecast as i:625\n",
            "  Class: 9 Correct match:4 Number of elements:1000 Forecast as i:53\n",
            " \n",
            "\n",
            " precisions for all classes: [0.07352256863657515, 0.24914187643020594, 0, 0.0, 0.0, 0, 0.17513661202185793, 0.2222222222222222, 0.3568, 0.07547169811320754]\n",
            "  recall for all classes:[0.158, 0.871, 0, 0.0, 0.0, 0, 0.641, 0.002, 0.223, 0.004]\n",
            "  Accuracy0.1899\n",
            "ACCURACY ON TEST SET:  0.1899\n",
            "ACCURACY ON TRAIN SET  0.23692\n",
            "\n",
            "-------------- Epoch:9--------------\n",
            "\n",
            "  Class: 0 Correct match:609 Number of elements:1000 Forecast as i:2923\n",
            "  Class: 1 Correct match:723 Number of elements:1000 Forecast as i:2019\n",
            "  Class: 2 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 3 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 4 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 5 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 6 Correct match:824 Number of elements:1000 Forecast as i:4595\n",
            "  Class: 7 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            "  Class: 8 Correct match:231 Number of elements:1000 Forecast as i:463\n",
            "  Class: 9 Correct match:0 Number of elements:1000 Forecast as i:0\n",
            " \n",
            "\n",
            " precisions for all classes: [0.20834758809442352, 0.35809806835066865, 0, 0, 0, 0, 0.17932535364526658, 0, 0.49892008639308855, 0]\n",
            "  recall for all classes:[0.609, 0.723, 0, 0, 0, 0, 0.824, 0, 0.231, 0]\n",
            "  Accuracy0.2387\n",
            "ACCURACY ON TEST SET:  0.2387\n",
            "ACCURACY ON TRAIN SET  0.27032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7eff13acc080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFECABAlAABRAgAQJQAAUQIAEDVMG2xcuBPj9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqwxve5wqJHv"
      },
      "source": [
        "## 2) Test of the  CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvKSXmN5zUuh"
      },
      "source": [
        "Here is an relatively efficient architecture that we found fot the CNN. We tried another  architecture with 32 filters but even if it was efficient, the process was too long to be able to optimize it (6h for an epoch). In this [website](https://https://www.tensorflow.org/tutorials/images/cnn?fbclid=IwAR3mSGlmGEbMqNltwc0u2rA_HiyrL4X5SiT0fHSS-990WxQY0Ru9NSaFORA), they even tried with 64 filters, on two convolution layers but we are not able to do it with our basic model  wich was not build for this purpose.\n",
        "\n",
        "CAUTION: The next cell needs about 40 min to complete one epoch!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuoq52J2p2iq",
        "outputId": "2ac5b383-0933-4297-c03e-7313ffb4a728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "np.random.seed(42)\n",
        "# define the model \n",
        "CNNetwork=model(0.003,\"CNN\")\n",
        "filters_list=CNNetwork.create_filters(5,3)\n",
        "layer1=convolution_layer(filters_list)\n",
        "layer2=relu_layer_conv(10,5)\n",
        "layer3=pooling_layer(10,5,[5,5])\n",
        "layer4=convert_layer()\n",
        "layer5=net_layer(180,10,10)\n",
        "layer6=relu_layer_mlp(10,10,10)\n",
        "\n",
        "CNNetwork.add_layer(layer1)\n",
        "CNNetwork.add_layer(layer2)\n",
        "CNNetwork.add_layer(layer3)\n",
        "CNNetwork.add_layer(layer4)\n",
        "CNNetwork.add_layer(layer5)\n",
        "CNNetwork.add_layer(layer6)\n",
        "\n",
        "#create the input for the test set \n",
        "test_list,test_labels_list=CNNetwork.create_input(test_images, test_labels, len(test_labels),True)\n",
        "start_time=time.time()\n",
        "\n",
        "accuracy_train_epoch_list=[]\n",
        "accuracy_test_epoch_list=[]\n",
        "#iterate over the epoch\n",
        "for epoch in range (5):\n",
        "  print(\"\\n-------- Epoch:\"+str(epoch)+\"--------\\n\")\n",
        "  \n",
        "  #create the batch list for the training\n",
        "  batch_list,batch_labels_list=CNNetwork.create_input(train_images, train_labels, 10,True)\n",
        "  \n",
        "  \n",
        "  counter=0\n",
        "  accuracy_list=[]\n",
        "  batch_number_list=[]\n",
        "  \n",
        "  #train for each batch\n",
        "  for b,l in zip(batch_list,batch_labels_list):\n",
        "    accuracy_list=[]\n",
        "    batch_number_list=[]\n",
        "    # because the process can be long, we print  and  record every 500 batch the \n",
        "    #time  and the accuracy on the all the batches that went into the network for now\n",
        "    \n",
        "    if counter%500==0:\n",
        "      curr_accuracy=CNNetwork.correct_match/((counter+1)*10)\n",
        "      print(\"Execution time :\"+ str( (time.time() - start_time))+\" batch: \"+str(counter))\n",
        "      print(\"Network accuracy\", curr_accuracy)\n",
        "      batch_number_list.append(counter)\n",
        "      accuracy_list.append(curr_accuracy)\n",
        "\n",
        "    counter+=1\n",
        "\n",
        "    #train the model\n",
        "    CNNetwork.fit(b,l)\n",
        "\n",
        "  \n",
        "  \n",
        "  print(\"Execution time: %s secondes ---\" % (time.time() - start_time))\n",
        "\n",
        "  train_set_accuracy=CNNetwork.correct_match/len(train_labels)\n",
        "  print(\"accuracy on train_set\",train_set_accuracy)\n",
        "  accuracy_train_epoch_list.append(train_set_accuracy)\n",
        "  CNNetwork.correct_match=0\n",
        "  test_accuracy,precision,recall=CNNetwork.prediction(test_list[0][::10],test_labels_list[0][::10],10)\n",
        "  print(\"accuracy on test_set\", test_accuracy)\n",
        "  accuracy_test_epoch_list.append(test_accuracy)\n",
        "  CNNetwork.correct_match=0\n",
        "\n",
        "  print(\"Execution time: %s secondes ---\" % (time.time() - start_time))\n",
        "\n",
        "#plot the results\n",
        "\n",
        "plt.plot(range(5),accuracy_train_epoch_list,label=\"train accuracy over epoch\")\n",
        "plt.plot(range(5),accuracy_test_epoch_list,label=\"test accuracy over epoch\")\n",
        "plt.legend(loc='best')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------- Epoch:0--------\n",
            "\n",
            "Execution time :0.9316229820251465 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :240.98727798461914 batch: 500\n",
            "Network accuracy 0.10978043912175649\n",
            "Execution time :482.58077335357666 batch: 1000\n",
            "Network accuracy 0.11398601398601399\n",
            "Execution time :724.4053840637207 batch: 1500\n",
            "Network accuracy 0.1211858760826116\n",
            "Execution time :965.8223648071289 batch: 2000\n",
            "Network accuracy 0.1256871564217891\n",
            "Execution time :1207.250113248825 batch: 2500\n",
            "Network accuracy 0.13114754098360656\n",
            "Execution time :1448.1231153011322 batch: 3000\n",
            "Network accuracy 0.13492169276907698\n",
            "Execution time :1689.2882549762726 batch: 3500\n",
            "Network accuracy 0.13710368466152528\n",
            "Execution time :1930.7479183673859 batch: 4000\n",
            "Network accuracy 0.1379655086228443\n",
            "Execution time :2171.6743063926697 batch: 4500\n",
            "Network accuracy 0.13879137969340147\n",
            "Execution time: 2412.1989467144012 secondes ---\n",
            "accuracy on train_set 0.14154\n",
            "  Class: 0 Correct match:63 Number of elements:103 Forecast as i:439\n",
            "  Class: 1 Correct match:4 Number of elements:102 Forecast as i:11\n",
            "  Class: 2 Correct match:1 Number of elements:96 Forecast as i:2\n",
            "  Class: 3 Correct match:30 Number of elements:80 Forecast as i:303\n",
            "  Class: 4 Correct match:0 Number of elements:105 Forecast as i:0\n",
            "  Class: 5 Correct match:24 Number of elements:104 Forecast as i:76\n",
            "  Class: 6 Correct match:0 Number of elements:92 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:104 Forecast as i:0\n",
            "  Class: 8 Correct match:19 Number of elements:115 Forecast as i:41\n",
            "  Class: 9 Correct match:37 Number of elements:99 Forecast as i:128\n",
            " \n",
            "\n",
            " precisions for all classes: [0.14350797266514806, 0.36363636363636365, 0.5, 0.09900990099009901, 0, 0.3157894736842105, 0, 0, 0.4634146341463415, 0.2890625]\n",
            "  recall for all classes:[0.6116504854368932, 0.0392156862745098, 0.010416666666666666, 0.375, 0, 0.23076923076923078, 0, 0, 0.16521739130434782, 0.37373737373737376]\n",
            "  Accuracy0.178\n",
            "accuracy on test_set 0.178\n",
            "Execution time: 2458.317542552948 secondes ---\n",
            "\n",
            "-------- Epoch:1--------\n",
            "\n",
            "Execution time :2459.4298419952393 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :2701.2104771137238 batch: 500\n",
            "Network accuracy 0.1692614770459082\n",
            "Execution time :2942.561980485916 batch: 1000\n",
            "Network accuracy 0.17032967032967034\n",
            "Execution time :3183.825321674347 batch: 1500\n",
            "Network accuracy 0.173217854763491\n",
            "Execution time :3425.426552772522 batch: 2000\n",
            "Network accuracy 0.17256371814092952\n",
            "Execution time :3667.4592101573944 batch: 2500\n",
            "Network accuracy 0.17353058776489405\n",
            "Execution time :3910.5448331832886 batch: 3000\n",
            "Network accuracy 0.1732755748083972\n",
            "Execution time :4152.610753774643 batch: 3500\n",
            "Network accuracy 0.175235646958012\n",
            "Execution time :4395.36775970459 batch: 4000\n",
            "Network accuracy 0.17438140464883778\n",
            "Execution time :4637.44845700264 batch: 4500\n",
            "Network accuracy 0.173472561652966\n",
            "Execution time: 4879.706797361374 secondes ---\n",
            "accuracy on train_set 0.17372\n",
            "  Class: 0 Correct match:78 Number of elements:103 Forecast as i:615\n",
            "  Class: 1 Correct match:4 Number of elements:102 Forecast as i:6\n",
            "  Class: 2 Correct match:1 Number of elements:96 Forecast as i:3\n",
            "  Class: 3 Correct match:10 Number of elements:80 Forecast as i:55\n",
            "  Class: 4 Correct match:0 Number of elements:105 Forecast as i:0\n",
            "  Class: 5 Correct match:21 Number of elements:104 Forecast as i:66\n",
            "  Class: 6 Correct match:0 Number of elements:92 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:104 Forecast as i:0\n",
            "  Class: 8 Correct match:61 Number of elements:115 Forecast as i:142\n",
            "  Class: 9 Correct match:40 Number of elements:99 Forecast as i:113\n",
            " \n",
            "\n",
            " precisions for all classes: [0.12682926829268293, 0.6666666666666666, 0.3333333333333333, 0.18181818181818182, 0, 0.3181818181818182, 0, 0, 0.4295774647887324, 0.35398230088495575]\n",
            "  recall for all classes:[0.7572815533980582, 0.0392156862745098, 0.010416666666666666, 0.125, 0, 0.20192307692307693, 0, 0, 0.5304347826086957, 0.40404040404040403]\n",
            "  Accuracy0.215\n",
            "accuracy on test_set 0.215\n",
            "Execution time: 4925.712766170502 secondes ---\n",
            "\n",
            "-------- Epoch:2--------\n",
            "\n",
            "Execution time :4928.528081417084 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :5169.79304766655 batch: 500\n",
            "Network accuracy 0.17764471057884232\n",
            "Execution time :5411.085499286652 batch: 1000\n",
            "Network accuracy 0.17522477522477523\n",
            "Execution time :5653.210514307022 batch: 1500\n",
            "Network accuracy 0.1787475016655563\n",
            "Execution time :5894.212076425552 batch: 2000\n",
            "Network accuracy 0.17661169415292355\n",
            "Execution time :6135.666102409363 batch: 2500\n",
            "Network accuracy 0.17900839664134346\n",
            "Execution time :6376.193442583084 batch: 3000\n",
            "Network accuracy 0.18070643118960347\n",
            "Execution time :6617.587439060211 batch: 3500\n",
            "Network accuracy 0.18189088831762354\n",
            "Execution time :6858.194238185883 batch: 4000\n",
            "Network accuracy 0.18247938015496126\n",
            "Execution time :7099.144018650055 batch: 4500\n",
            "Network accuracy 0.18422572761608533\n",
            "Execution time: 7340.325326681137 secondes ---\n",
            "accuracy on train_set 0.1849\n",
            "  Class: 0 Correct match:52 Number of elements:103 Forecast as i:355\n",
            "  Class: 1 Correct match:0 Number of elements:102 Forecast as i:0\n",
            "  Class: 2 Correct match:15 Number of elements:96 Forecast as i:61\n",
            "  Class: 3 Correct match:21 Number of elements:80 Forecast as i:94\n",
            "  Class: 4 Correct match:0 Number of elements:105 Forecast as i:0\n",
            "  Class: 5 Correct match:11 Number of elements:104 Forecast as i:24\n",
            "  Class: 6 Correct match:0 Number of elements:92 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:104 Forecast as i:0\n",
            "  Class: 8 Correct match:18 Number of elements:115 Forecast as i:36\n",
            "  Class: 9 Correct match:74 Number of elements:99 Forecast as i:430\n",
            " \n",
            "\n",
            " precisions for all classes: [0.14647887323943662, 0, 0.2459016393442623, 0.22340425531914893, 0, 0.4583333333333333, 0, 0, 0.5, 0.17209302325581396]\n",
            "  recall for all classes:[0.5048543689320388, 0, 0.15625, 0.2625, 0, 0.10576923076923077, 0, 0, 0.1565217391304348, 0.7474747474747475]\n",
            "  Accuracy0.191\n",
            "accuracy on test_set 0.191\n",
            "Execution time: 7386.557916879654 secondes ---\n",
            "\n",
            "-------- Epoch:3--------\n",
            "\n",
            "Execution time :7388.109009027481 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :7630.082445144653 batch: 500\n",
            "Network accuracy 0.18602794411177645\n",
            "Execution time :7870.357719898224 batch: 1000\n",
            "Network accuracy 0.18561438561438562\n",
            "Execution time :8111.659945011139 batch: 1500\n",
            "Network accuracy 0.18407728181212524\n",
            "Execution time :8352.074658155441 batch: 2000\n",
            "Network accuracy 0.1874062968515742\n",
            "Execution time :8592.697197437286 batch: 2500\n",
            "Network accuracy 0.18768492602958817\n",
            "Execution time :8833.379056692123 batch: 3000\n",
            "Network accuracy 0.18710429856714428\n",
            "Execution time :9075.116748809814 batch: 3500\n",
            "Network accuracy 0.18674664381605255\n",
            "Execution time :9316.089438199997 batch: 4000\n",
            "Network accuracy 0.1865533616595851\n",
            "Execution time :9556.86213517189 batch: 4500\n",
            "Network accuracy 0.1869362363919129\n",
            "Execution time: 9798.15900015831 secondes ---\n",
            "accuracy on train_set 0.18716\n",
            "  Class: 0 Correct match:51 Number of elements:103 Forecast as i:321\n",
            "  Class: 1 Correct match:10 Number of elements:102 Forecast as i:16\n",
            "  Class: 2 Correct match:1 Number of elements:96 Forecast as i:4\n",
            "  Class: 3 Correct match:32 Number of elements:80 Forecast as i:162\n",
            "  Class: 4 Correct match:0 Number of elements:105 Forecast as i:0\n",
            "  Class: 5 Correct match:4 Number of elements:104 Forecast as i:6\n",
            "  Class: 6 Correct match:0 Number of elements:92 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:104 Forecast as i:0\n",
            "  Class: 8 Correct match:91 Number of elements:115 Forecast as i:491\n",
            "  Class: 9 Correct match:0 Number of elements:99 Forecast as i:0\n",
            " \n",
            "\n",
            " precisions for all classes: [0.1588785046728972, 0.625, 0.25, 0.19753086419753085, 0, 0.6666666666666666, 0, 0, 0.18533604887983707, 0]\n",
            "  recall for all classes:[0.49514563106796117, 0.09803921568627451, 0.010416666666666666, 0.4, 0, 0.038461538461538464, 0, 0, 0.7913043478260869, 0]\n",
            "  Accuracy0.189\n",
            "accuracy on test_set 0.189\n",
            "Execution time: 9844.220123767853 secondes ---\n",
            "\n",
            "-------- Epoch:4--------\n",
            "\n",
            "Execution time :9847.83021235466 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :10088.391951084137 batch: 500\n",
            "Network accuracy 0.18023952095808382\n",
            "Execution time :10329.995534181595 batch: 1000\n",
            "Network accuracy 0.189010989010989\n",
            "Execution time :10571.31162571907 batch: 1500\n",
            "Network accuracy 0.1900066622251832\n",
            "Execution time :10811.496936321259 batch: 2000\n",
            "Network accuracy 0.18625687156421789\n",
            "Execution time :11052.330330133438 batch: 2500\n",
            "Network accuracy 0.1864454218312675\n",
            "Execution time :11293.066430807114 batch: 3000\n",
            "Network accuracy 0.18563812062645785\n",
            "Execution time :11533.568028211594 batch: 3500\n",
            "Network accuracy 0.18574692944872895\n",
            "Execution time :11773.4815762043 batch: 4000\n",
            "Network accuracy 0.1850037490627343\n",
            "Execution time :12014.296674728394 batch: 4500\n",
            "Network accuracy 0.18615863141524105\n",
            "Execution time: 12254.230166435242 secondes ---\n",
            "accuracy on train_set 0.1854\n",
            "  Class: 0 Correct match:74 Number of elements:103 Forecast as i:596\n",
            "  Class: 1 Correct match:48 Number of elements:102 Forecast as i:189\n",
            "  Class: 2 Correct match:23 Number of elements:96 Forecast as i:108\n",
            "  Class: 3 Correct match:18 Number of elements:80 Forecast as i:52\n",
            "  Class: 4 Correct match:0 Number of elements:105 Forecast as i:0\n",
            "  Class: 5 Correct match:15 Number of elements:104 Forecast as i:39\n",
            "  Class: 6 Correct match:0 Number of elements:92 Forecast as i:0\n",
            "  Class: 7 Correct match:0 Number of elements:104 Forecast as i:0\n",
            "  Class: 8 Correct match:4 Number of elements:115 Forecast as i:8\n",
            "  Class: 9 Correct match:3 Number of elements:99 Forecast as i:8\n",
            " \n",
            "\n",
            " precisions for all classes: [0.12416107382550336, 0.25396825396825395, 0.21296296296296297, 0.34615384615384615, 0, 0.38461538461538464, 0, 0, 0.5, 0.375]\n",
            "  recall for all classes:[0.7184466019417476, 0.47058823529411764, 0.23958333333333334, 0.225, 0, 0.14423076923076922, 0, 0, 0.034782608695652174, 0.030303030303030304]\n",
            "  Accuracy0.185\n",
            "accuracy on test_set 0.185\n",
            "Execution time: 12300.124540805817 secondes ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7eff13b289e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3wVZdbA8d9JI4QQCBCKhKYgJSGh\nJBFQpImgIFYQFQUUsK/vq7KWteuurui+u5ZVEQWsNEXRBYVVsCMJVSkiTRJACAQCAULaef+YyzWE\nQG4gydwk5/v53E9yp54M3DNzn3nmPKKqGGOMqboC3A7AGGNM+bJEb4wxVZwlemOMqeIs0RtjTBVn\nid4YY6q4ILcDKKpBgwbasmVLt8MwxphKZenSpbtVNaq4eX6X6Fu2bElKSorbYRhjTKUiIr+daJ41\n3RhjTBVnid4YY6o4S/TGGFPF+V0bvTH+JDc3l7S0NLKzs90OxRgAQkNDiY6OJjg42Od1LNEbcxJp\naWnUrl2bli1bIiJuh2OqOVVlz549pKWl0apVK5/Xs6YbY04iOzub+vXrW5I3fkFEqF+/fqm/YVqi\nN6YEluSNPzmV/4+W6Kuzn2ZB+nq3ozDGlDNL9NXVsrfhg5vg9b7w63/djsacwL59+/j3v/99Sute\nfPHF7Nu3r4wjMuVp0aJFDB48uMy3a4m+Ovr9J5h7L7Q4DyJbwntDYcnrbkdlinGyRJ+Xl3fSdefO\nnUvdunXLI6zToqoUFBS4HYZPSjrGlYUl+uomOxNm3AA1I2HoFLhxHrS50En88+6Dgny3IzSF3H//\n/WzcuJFOnToxfvx4Fi1aRM+ePRkyZAgdOnQA4LLLLqNr167ExMQwceJE77otW7Zk9+7dbNmyhfbt\n2zN27FhiYmK48MILOXz48HH7+uSTTzjnnHPo3LkzF1xwATt37gQgKyuL0aNH07FjR+Li4vjggw8A\n+Oyzz+jSpQvx8fH069cPgMcee4znnnvOu83Y2Fi2bNnCli1baNu2LTfccAOxsbGkpqZy6623kpCQ\nQExMDI8++qh3neTkZHr06EF8fDxJSUkcOHCA888/nxUrVniXOe+881i5cuUx8WdnZ3vj7Ny5MwsX\nLgSgW7durF692rtc7969SUlJ4eDBg9x4440kJSXRuXNnPv74YwCmTJnCkCFD6Nu3r/fvKuydd94h\nKSmJTp06cfPNN5Of73xmwsPD+d///V9iYmLo168f6enpAKxYsYJu3boRFxfH5Zdfzt69ewHYsGED\nF1xwAfHx8XTp0oWNGzd6j/dVV11Fu3btuO666yiTUQBV1a9eXbt2VVNOCgpUp12n+lik6pbv/5ie\nn6c6737VRyNU37lKNXu/ezH6mTVr1nh/f2zOzzrs1e/L9PXYnJ9Puv/NmzdrTEyM9/3ChQs1LCxM\nN23a5J22Z88eVVU9dOiQxsTE6O7du1VVtUWLFpqenq6bN2/WwMBAXb58uaqqDh06VN9+++3j9pWR\nkaEFBQWqqvr666/r3Xffraqqf/7zn/Wuu+46Zrldu3ZpdHS0N46jMTz66KM6YcIE77IxMTG6efNm\n3bx5s4qI/vDDD8fFnZeXp7169dKVK1fqkSNHtFWrVrpkyRJVVc3MzNTc3FydMmWKN4ZffvlFi8sT\nzz33nI4ePVpVVdeuXavNmjXTw4cP6z/+8Q995JFHVFV1+/btevbZZ6uq6gMPPOA9Dnv37tU2bdpo\nVlaWTp48WZs2beqNr7A1a9bo4MGDNScnR1VVb731Vp06daqqqgL6zjvvqKrq448/rrfffruqqnbs\n2FEXLVqkqqoPP/yw9+9ISkrSDz/8UFVVDx8+rAcPHtSFCxdqRESEpqaman5+vnbr1k2/+eabYuMo\nCkjRE+RVu6KvTha/Ams/gf6PQ4vuf0wPCISBT8Ogf8CGL+CNAbAv1b04zUklJSUd04f6hRdeID4+\nnm7dupGamsqvv/563DqtWrWiU6dOAHTt2pUtW7Yct0xaWhoDBgygY8eOTJgwwXsV/N///pfbb7/d\nu1xkZCSLFy/m/PPP98ZRr169EuNu0aIF3bp1876fMWMGXbp0oXPnzqxevZo1a9bwyy+/0KRJExIT\nEwGIiIggKCiIoUOH8umnn5Kbm8ubb77JqFGjjtv+t99+y4gRIwBo164dLVq0YP369QwbNoxZs2Z5\n93nVVVcBMH/+fJ555hk6depE7969yc7OZuvWrQD079+/2L/piy++YOnSpSQmJtKpUye++OILNm3a\nBEBAQABXX301ACNGjODbb78lMzOTffv20atXLwBGjhzJ119/zYEDB9i2bRuXX3454DwEFRYWBjj/\nvtHR0QQEBNCpU6di/61Kyx6Yqi62/ggLHoZ2g6H7HcUvk3iT02Y/c5Rzk/aaaRDdtSKj9GuPXhLj\ndggA1KpVy/v7okWL+O9//8sPP/xAWFiYN2EVVaNGDe/vgYGBxTbd3Hnnndx9990MGTKERYsW8dhj\nj5U6tqCgoGPa3wvHUjjuzZs389xzz5GcnExkZCSjRo06ad/wsLAw+vfvz8cff8yMGTNYunSpzzE1\nbdqU+vXrs2rVKqZPn86rr74KOK0ZH3zwAW3btj1m+R9//PGYWAtTVUaOHMnTTz9d4n5PtVtu0X+r\nsrhPYFf01cHB3U7yrhMNl74MJ/sP2Lof3LQAgkNhysWw+qMKC9Mcr3bt2hw4cOCE8zMzM4mMjCQs\nLIx169axePHiU95XZmYmTZs2BWDq1Kne6f379+fll1/2vt+7dy/dunXj66+/ZvPmzQBkZGQAzn2B\nZcuWAbBs2TLv/KL2799PrVq1qFOnDjt37mTevHkAtG3blh07dpCcnAzAgQMHvIluzJgx/OlPfyIx\nMZHIyMjjttmzZ0/effddANavX8/WrVu9Sfzqq6/m2WefJTMzk7i4OAAGDBjAiy++6G0DX758eYnH\nqF+/fsyaNYtdu3Z5/+7ffnOqAxcUFHi/Obz33nucd9551KlTh8jISL755hsA3n77bXr16kXt2rWJ\njo7mo4+cz9eRI0c4dOhQifs/VZboq7qCfPhwLBzaA8Pegpo+9MJo2A7GfAmN42DmSPjmeSiLG0Km\n1OrXr8+5555LbGws48ePP27+wIEDycvLo3379tx///3HNI2U1mOPPcbQoUPp2rUrDRo08E5/6KGH\n2Lt3L7GxscTHx7Nw4UKioqKYOHEiV1xxBfHx8d4miyuvvJKMjAxiYmJ46aWXOPvss4vdV3x8PJ07\nd6Zdu3Zce+21nHvuuQCEhIQwffp07rzzTuLj4+nfv7/3Sr9r165EREQwevToYrd52223UVBQQMeO\nHbn66quZMmWK9+r4qquuYtq0aQwbNsy7/MMPP0xubi5xcXHExMTw8MMPl3iMOnTowFNPPcWFF15I\nXFwc/fv3Z8eOHYDzjWXJkiXExsby5Zdf8sgjjwDOSXP8+PHExcWxYsUK7/S3336bF154gbi4OHr0\n6MHvv/9e4v5PlaiffYATEhLUBh4pQ4uegUVPwyX/gq6jSrdubjZ8fDv8PAvir3W2ERRSLmH6q7Vr\n19K+fXu3wzDA9u3b6d27N+vWrSMgwP+uUcPDw8nKyqqQfRX3/1JElqpqQnHL+9/RMmVnwxdOoo+/\nBrqMLP36waFw5STo/QCsfA/evgwOZZR9nMaU4K233uKcc87hr3/9q18meX9nR6yqytzmNNk0bA+D\nnj95u/zJiEDv++GKSZCWDJP6we7je3UYU55uuOEGUlNTGTp0qNuhnFBFXc2fCp8SvYgMFJFfRGSD\niNxfzPy7RWSNiKwSkS9EpEWheZ+JyD4R+bQsAzcnkZ/r3HzNO+K0y4cU34OgVOKGwshPnAeuJl0A\nm78+/W0aYypEiYleRAKBl4GLgA7ANSLSochiy4EEVY0DZgHPFpo3Abi+bMI1PlnwKKQtgSEvQIM2\nZbfd5t1gzBcQ3gjevtypl2OM8Xu+XNEnARtUdZOq5gDTgEsLL6CqC1X1aN+gxUB0oXlfACfuH2bK\n1po5sPhlSLoZYq8s++3XawU3zYeWPWHOHbDgEagkdUuMqa58SfRNgcKPSaZ5pp3ITcC80gQhIuNE\nJEVEUo7WhzCnYM9Gp5dM065w4VPlt5+adeG6mdB1NHz3L5hxPeQcLL/9GWNOS5nejBWREUACTnON\nz1R1oqomqGpCVFRUWYZUfeQedoqVBQQ6xcrKuxtkYDAM/j8Y8DdY9x+YfDHs31G++6yGTqdMMcA/\n//nPcn0Qx5yeokXgyosviX4b0KzQ+2jPtGOIyAXAX4AhqnqkbMIzPps7Hnb+DFe8DnWbV8w+RaD7\n7XDN+05PnEn9YMeqitl3NVEVEn1lKvVbmWItDV8SfTLQRkRaiUgIMByYU3gBEekMvIaT5HeVfZjm\npJa/A8vfhp73Qpv+Fb//thfBjZ85T8++ORB+KVXLnTmJomWKASZMmEBiYiJxcXHe8r4HDx5k0KBB\nxMfHExsby/Tp03nhhRfYvn07ffr0oU+fPsdt+4knniAxMZHY2FjGjRvnLQVwovK5f//73+nYsSPx\n8fHcf7/T+e5oyV+A3bt307JlS+D4Ur9ZWVn069ePLl260LFjR29JYHD6yMfFxREfH8/111/PgQMH\naNWqFbm5uYBTLqHw+6O2bNlC3759iYuLo1+/fmzdupXMzExatGjhrbdz8OBBmjVrRm5uLhs3bmTg\nwIF07dqVnj17sm7dOgBGjRrFLbfcwjnnnMOf//znY/aRn5/P+PHjvcf7tddeA5waQ+effz6DBg2i\nbdu23HLLLd59vv/++3Ts2JHY2Fjuu+8+77aKK+sMsGbNGnr37s2ZZ57JCy+84MP/ilNworKWhV/A\nxcB6YCPwF8+0J3ASO8B/gZ3ACs9rTqF1vwHSgcM47fsDTrYvK1NcSjt+Un2yoeqUwU65YTdlbld9\n9XzVR+uofv+SUxa5kjumHOzc+1TfvLhsX3PvO+n+i5Yp/vzzz3Xs2LFaUFCg+fn5OmjQIP3qq690\n1qxZOmbMGO9y+/btU9U/ShUXp3AZ3hEjRuicOXNUtfjyuXPnztXu3bvrwYMHj1m3V69empycrKqq\n6enp2qJFC1XV40r95ubmamZmpne5s846SwsKCvTnn3/WNm3aeGM8uvyoUaN09uzZqqr62muveUsm\nFzZ48GCdMmWKqqq+8cYbeumll6qq6pAhQ/TLL79UVdVp06bpTTfdpKqqffv21fXr16uq6uLFi7VP\nnz6qqjpy5EgdNGiQ5uUd//l57bXX9Mknn1RV1ezsbO3atatu2rRJFy5cqDVq1NCNGzdqXl6eXnDB\nBTpz5kzdtm2bNmvWTHft2qW5ubnap08fnT179knLOnfv3l2zs7M1PT1d69Wr5y2BfDKlLVPsU/VK\nVZ0LzC0y7ZFCv19wknV7+rIPcwqy9zvt8qF14co3nPZ5N0U0gdFz4cNx8PmDTnPOxROc9nxTJubP\nn8/8+fPp3Lkz4Dyk8+uvv9KzZ0/uuece7rvvPgYPHkzPniV/7BYuXMizzz7LoUOHvPVpevfufVz5\nXHBKFY8ePdpbSteXssSFS/2qKg8++CBff/01AQEBbNu2jZ07d/Lll18ydOhQb22do8uPGTOGZ599\nlssuu4zJkyfz+uvHj4D2ww8/8OGHHwJw/fXXe6/Gr776aqZPn06fPn2YNm0at912G1lZWXz//ffH\nPHB15MgfLcxDhw4lMPD4z8/8+fNZtWqVt1hZZmYmv/76KyEhISQlJXHmmWcCcM011/Dtt98SHBxM\n7969OXqv8brrruPrr78mMDDwhGWdBw0aRI0aNahRowYNGzZk586dREdHU5asTHFlpep0b9y7BUZ9\nCuEN3Y7IEVILhr0NXzwO3/3TiW/oFN+Kqfm7i55xOwJUlQceeICbb775uHnLli1j7ty5PPTQQ/Tr\n189bPKs42dnZ3HbbbaSkpNCsWTMee+yxk5YJPpHCZYmLrl+41O+7775Leno6S5cuJTg4mJYtW550\nf+eeey5btmxh0aJF5OfnExsb63NMQ4YM4cEHHyQjI4OlS5fSt29fDh48SN26dY8ZpepEsRamqrz4\n4osMGDDgmOmLFi06rgyxP5UlLspKIFRWP74Kaz6GCx6FFj3cjuZYAQHO4CZDXoIt38AbF0JG8eVq\nzckVLVM8YMAA3nzzTe/j9tu2bWPXrl1s376dsLAwRowYwfjx472lgk9U5vhokm3QoAFZWVneK9YT\nlc/t378/kydP9t7YLVyW+Ght+KPbKE5mZiYNGzYkODiYhQsXekv79u3bl5kzZ7Jnz55jtgtO2YNr\nr732hNUqe/TowbRp0wDnRHL0W0x4eDiJiYncddddDB48mMDAQCIiImjVqhUzZ84EnARedCjC4gwY\nMIBXXnnFe39g/fr1HDzodCVesmQJmzdvpqCggOnTp3PeeeeRlJTEV199xe7du8nPz+f999+nV69e\nJyzrXFHsir4ySl0C8x+CtoOgx5/cjubEulwPkS1g+vVOj5zh7zlP1xqfFS5TfNFFFzFhwgTWrl1L\n9+7OCGHh4eG88847bNiwgfHjxxMQEEBwcDCvvPIKAOPGjWPgwIGcccYZ3jFUAerWrcvYsWOJjY2l\ncePG3hGdwCmfe/PNN/PII48QHBzMzJkzGThwICtWrCAhIYGQkBAuvvhi/va3v3HvvfcybNgwJk6c\nyKBBg074d1x33XVccskldOzYkYSEBNq1awdATEwMf/nLX+jVqxeBgYF07tyZKVOmeNd56KGHuOaa\na4rd5osvvsjo0aOZMGECUVFRTJ482Tvv6quvZujQoSxatMg77d133+XWW2/lqaeeIjc3l+HDhxMf\nH3/S4z9mzBi2bNlCly5dUFWioqK8J8HExETuuOMONmzYQJ8+fbj88ssJCAjgmWeeoU+fPqgqgwYN\n4tJLnedLj5Z1LigooGHDhixYsOCk+y5LVqa4sjm4B17rCQFBcPPXlaNJZPcGeG8oZKbBpf926uZU\nElam2D2zZs3i448/5u23/a/UxqJFi3juuef49FN3SniVtkyxXdFXJgUFTkXKg7udMgSVIckDNGjt\n1MiZPgI+HAN7NjgVMU+1oqap8u68807mzZvH3LlzS17YlMgSfWXyzXOw8QvnidQzOrkdTemE1YPr\nZ8Mn/wNfPeMk+0tfdmreG1PEiy++6HYIJ9W7d2969+7tdhg+s0RfWWxcCAv/BnFXOzVmKqOgGnDZ\nv50r/C+egH1bnXb7cP8ue6Gqp9yjwpiydirN7dbrpjLYvx0+GANR7Zyr+cqcdESg5z0wdCr8vgom\n9YVd69yO6oRCQ0PZs2fPKX24jClrqsqePXu8zzf4yq7o/V1+Lswc7RQtGza1bAYR8Qcxl0GdZvD+\ncHijv9PXvnW/EleraNHR0aSlpWFVVY2/CA0NLfUDVZbo/d1/H4PUxc6Tr1Ft3Y6mbEV3hbFfwntX\nw7tDnadoE29yO6pjBAcHe59mNKaysqYbf7b2E/jhJUgcCx2vcjua8lG3Gdz0uXM1/5+74bMHoCDf\n7aiMqVIs0furjE3w0W1wRhcY8Fe3oylfNWrD8PfhnFtg8b9h2rVwxAYlM6asWKL3R0cHEZEAzyAi\nNUpcpdILDIKL/g4XPwe/zoc3L3IesDLGnDZL9P5o3n3w+09wxUSnhEB1kjQWrp3pFEN7vS9sW+p2\nRMZUepbo/c2K92DZVDjvbjh7QMnLV0VtLnCe/A2sAZMHOQOeG2NOmSV6f7JzNXx6N7TsCX3+4nY0\n7mrUAcZ+AY1jncHHv/mHU5rZGFNqluj9xZEDnkFEIpyulIHW85XwhjDyE4i5wqlv//EdkJfjdlTG\nVDo+JXoRGSgiv4jIBhG5v5j5d4vIGhFZJSJfiEiLQvNGisivntfIsgy+ylCFOXc6PW2uehNqN3I7\nIv8RXNM58Z3/Z1jxDrxzBRyq2FrexlR2JSZ6EQkEXgYuAjoA14hIhyKLLQcSVDUOmAU861m3HvAo\ncA6QBDwqIpFlF34VsWQirJ4N/R6Blue5HY3/CQiAvn+ByydC6o8w6QLYs9HtqIypNHy5ok8CNqjq\nJlXNAaYBlxZeQFUXquohz9vFwNHncwcAC1Q1Q1X3AguAgWUTehWRlgKf/wXOvgh63OV2NP4t/mq4\nYQ4c3usMZLLlW7cjMqZS8CXRNwVSC71P80w7kZuAeae4bvVyKANmjHQG1b78FefK1Zxci+7OTdpa\nUfDWZbD8XbcjMsbvlWlmEZERQAIwoZTrjRORFBFJqTbFowoK4MNxcHCXU8mxprVo+azemU73yxY9\n4OPbnHpAngGqjTHH8yXRbwOaFXof7Zl2DBG5APgLMERVj5RmXVWdqKoJqpoQFeXftcnLzLfPw4YF\nMPBpaNrF7Wgqn5qRMOID6DoKvv0/mDkScg6VuJox1ZEviT4ZaCMirUQkBBgOHPMEi4h0Bl7DSfK7\nCs36HLhQRCI9N2Ev9Eyr3jYtcgYR6TgUEvyrWmOlEhgMg/8JF/7VKQA3ZRAc+N3tqIzxOyUmelXN\nA+7ASdBrgRmqulpEnhCRIZ7FJgDhwEwRWSEiczzrZgBP4pwskoEnPNOqr/07nEFE6rdxklRlHkTE\nH4hAjztg+LuQvg5e7+eUjzDGeIm/jZyTkJCgKSkpbodRPvJzYeolsGMljF0IDdu5HVHVsmMlvDcc\njux3nkeoriUkTLUkIktVNaG4edbNoyJ98QRs/QEuecGSfHloEu/0yKl3pjNy1eJXrGyCMViirzjr\n/gPfv+C0yccNdTuaqiviDLjxM2h7MXx2P8y9F/Lz3I7KGFdZoq8IGZth9q3QpJPTy8aUr5BaMOxt\n6PEnSJ4E7w2D7Ey3ozLGNZboy1tutmcQEZzBvavDICL+ICAALnzSaSbb/BW8caFT496YasgSfXn7\n7H74fRVc/hpEtnQ7muqn60inv/2BHU6PnNQlbkdkTIWzRF+eVk6DpZPh3P+Bthe5HU31dWZvuOm/\nzti0UwbDT7PcjsiYCmWJvrzsWguf/i+0OBf6Pux2NCbqbBjzhfMU8gc3waK/W48cU21Yoi8PRw7A\n9OshJNzpz22DiPiHWvXhho8hbjgs+ptTayg32+2ojCl3loHKmip8chdkbHRK6tZu7HZEprCgGnD5\nq1C/NSx8CvZtdZ6qrdXA7ciMKTd2RV/WkifBzx9A34egVU+3ozHFEYFe4+GqybBjBbzeF9J/cTsq\nY8qNJfqylLYUPnsA2gyAc//X7WhMSWKvgFH/gdxDMKk/bFzodkTGlAtL9GXlUIZTKrd2E6dpwAYR\nqRyiE5ybtHWawjtXQspktyMypsxZNioLBQUw+2anRO6wKRBWz+2ITGlEtoAbP4ez+sCn/+MM7ViQ\n73ZUxpQZS/Rl4bv/g1/newYR6ep2NOZUhEbANdMhaRz88BJMHwFHstyOypgyYYn+dG3+Gr58CmKv\nhMQxbkdjTkdgEFw8AS56FtZ/BpMHQuZxA6IZU+lYoj8dB36HWTc5XfUu+ZcNIlJVnHOzc3WfsRkm\n9YPty92OyJjTYon+VOXnwawbIScLhr3lPF5vqo6zL3QGIA8IgskXO0MVGlNJWaI/VV8+Cb99B4P/\nDxq2dzsaUx4axTg9chq2d550/u5fVjbBVEo+PRkrIgOBfwGBwCRVfabI/POBfwJxwHBVnVVo3t+B\nQZ63T6rq9LII3FXr5sJ3/4SuoyF+uNvRmPJUu5HT1372LbDgEVj8KoTVh5p1oWbksa+wesdPqxkJ\nwTXd/itMNVdioheRQOBloD+QBiSLyBxVXVNosa3AKODeIusOAroAnYAawCIRmaeq+8smfBfs3QIf\n3eIMWzfwmRIXN1VAcE3nKdqU85z2+sN7necm0n9xfj+8FwpyT7x+UGihxF+v+JNEcSeM4DC772PK\nhC9X9EnABlXdBCAi04BLAW+iV9UtnnkFRdbtAHytqnlAnoisAgYCM04/dBccHUREgaFTITjU7YhM\nRQkIgKSxxc9ThZyDfyT9Y14ZhX7f5/zM2PTHySL/yIn3GRhy8hPCiV41atsJwhzDl0TfFEgt9D4N\nOMfH7a8EHhWR54EwoA+FThCVzucPwI6VMPx9qNfK7WiMvxCBGuHOq26z0q2be/iPpF/siaLQa99W\n5//f4b1O2YYTCQiC0Lonbkryvup6vmEcPUFE2BPdVVS5Vq9U1fkikgh8D6QDPwDHPXIoIuOAcQDN\nmzcvz5BO3aoZkPKmMw5pu4vdjsZUFcE1nVfEGaVbLzcbsvcVf0IoetLYvx12rnF+zzlw4m1KgHOC\n8PXew9FXaB0ICDy942DKlS+JfhtQ+DIl2jPNJ6r6V+CvACLyHrC+mGUmAhMBEhIS/K9bw651Tunh\n5j2g3yNuR2OM02wY3Lj0ZbDzc/9oQjpcwreIQ7thz69waC8cOdng6uIk++JOAhFNoN6Zf7ysG7Ir\nfEn0yUAbEWmFk+CHA9f6snHPjdy6qrpHROJweuXMP9VgXXEky2mXD6nlGUQk2O2IjDl1gcEQHuW8\nSiM/D7IzS2heKnTi2LvZ+WaRve/Y7dRqeGzir1/o99A6Zfd3mmOUmOhVNU9E7gA+x+le+aaqrhaR\nJ4AUVZ3jaZ6ZDUQCl4jI46oaAwQD34hzY2g/MMJzY7ZyODqIyJ5f4fqPnKsTY6qjwCBnhK5a9Uu3\n3pEsJ+lnbHJeezY6TxxvWgQr3zt22bD6nqR/1rEng3qtrFDgaRL1swdAEhISNCUlxe0wHMmT4D/3\nOIOInD/e7WiMqVpyDjndlTM2/nEiyNjknAgy03C6t3nUjCyS/AudEMLqWS8jQESWqmpCcfNsKMET\n2bbMGUSkdX847x63ozGm6gkJg0YdnFdRuYdh72+Fkr/nZJD6ozOCmxbqyV2jjnPVX7/oN4EzoVaU\nnQSwRF+8QxkwYySEN4IrJlqXM2NOIL9A2Xcoh4yDhV6Hcth7MIc9B3MQhIiaQdQODSYiNIiImsFE\nhAYTUTPI8zOY2jWCCAgokoyDa0LDds6rqLwjTlfTPUW+CWxbBqs/Ai3UsS+ktnMSOOa+gOeEEN6o\n2pwELNEXVVAAH90KB3bAjZ9Z26CpNlSVw7n57MnKYe8hJ1HvLZTA9x7KOW7evsO5Jyz/UyskkAAR\nDhw5+W05EQiv8UfiL3pCKKMdtVUAABrWSURBVP4k0ZA6UU2JaNaP8NAgAo+eKPJyIDP12BPAno3w\n+0+w7lMoKBRLcNgf9wCK3heo3aRKXeBZoi/q+385tcgvetYZZs6YSiq/QNlb6Op6r+dqOyPL87Nw\nEvcscySv6MPtjqAAIbJWCPXCQqhXK4T2jSOIrBVMvVo1qBcWTL3wGt559WqFEFkrmBpBgd44srLz\n2J+dS+bhXPZn57L/cJ7nZy77s/M8P3M54Pk9be9h9h/e751Wkto1nBNBbe8JIZKI0HOIqHkeEQ2D\niGgRTJ0QoaGm0yBnG5HZqYQf2krNA78RtOsXZP3nkJ9T6A+uWeibQKtj7wtENK10JwFL9IVt/ga+\neAJiLndGGjLGT6gqh3Lyj2seySju5UnimSe52q5dI8hJ3LVCaBQRSvsmEU6CDguhfq0Q77yjr4jQ\nIOQUmzkCA4Q6YcHUCQumlM8NA54TxZE/TgbFnSQOZBeelsv2fYdZ53l/4EhekeMQApzleTkiagTQ\nusY+2gan0ypwJy3YyRmHttNo/8/U+2U+QfrHSaAgIISciOYURLYioH5rgqPOIrCB5xtBnWZ++fCY\nJfqjDux06svXOwuGvFht2u6MO/LyC9h3OPe4K2rvz6Lt3j5cbdf3JOr2TSKKXF3/Ma9+eAh1w/64\n2q4MAgOEOjWDqVPz1J5hKShQsnI8J4oiJ4kDx5w4ziAjO5ctR99n57L/SB5Z2UdoqHtpGfA7LeV3\nWshOWu7ZSYuMdbTc9BWB8sdJIJcgdgU2ZndIU/aFRnOgVnOyw1uSW7clAXWbU7tWzePvUYQGERxY\nvt8QLNGD8zDIBzfBkQNww8f29J4pleKutjOKtGUf0959qOSr7XrhTmJu7LnaPuYqO6xQ8j7Nq+3q\nICBAnKQaGuw86VNKBQXKwZy8Y789HM5lbXYuPx7KIX//DoIzN1PzwG/UPpRKZHYaUTlptDm8krC9\n2d7t5GogadqA37Qxy7QRW7QxW7QRv2lj9gQ1pmbNULo0j+SVEWU/7rQleoCFf4Ut38Blrxbf1ctU\ne/sO5fDJyu1sTD9Y7I3JnBNcbQcHCpGFrq7bnxFxzNV14aaS+rVCqBsWQkhQ5Wr/reoCAoTaocHU\nDg2mad3ixhY4Ezj3+MmqkLULzdjIkV0byEvfQP09m2i4bzPnZX5HUN5B76IFBLBXG7FjfyLwdpn/\nDZbof/kMvv0HdBkJna5xOxrjR1SVHzdnMG3JVub+/Ds5eQXeq+16tUJoUieUmDMijm8iKfSzdg27\n2q62RKB2I6R2I0Jb9Dh2nioc3O3tGRSQsYn6GZuoX6uUpSl8VL0T/d7fYPbN0Lij08vGGGBP1hE+\nWJbGtCWpbNp9kNqhQQxPbMbwxOZ0OCPC7fBMVSDyR82h5r5WfT911TfR5x2BmSOdM+uwt2wQkWqu\noED5buNupi1JZf6a38nNVxJbRnJ7n9Zc3LEJNUMqz81LY4qqvon+8wedYeGuftfpFmWqpZ37s5mZ\nksr0lFRSMw4TGRbMDd1bMjyxGW0a2U15UzVUz0T/0yynYFn3O6D9YLejMRUsv0D5av0u3l+Sypfr\ndpFfoHQ/sz7jB7RjQEyjStX10BhfVL9En/4LzPkTNOsGFzzmdjSmAm3bd5jpyanMTEllR2Y2DcJD\nGNvzTIYnNqNlg1puh2dMualeiT7noDOISHBNGDrZBhGpBnLzC/hi7S6mJW/lq/XpAPRsE8UjgzvQ\nr30j68poqoXqk+hV4ZP/ca7or59d+jE6TaXy256DztX70jTSDxyhcUQod/ZpzdCEZjSrF+Z2eMZU\nqOqT6JdOhp9mQJ+/wFl93I7GlIMjefnMX72Taclb+W7DHgIE+rZryPDE5vRuG0VQOT9mboy/qh6J\nfvtymHcfnNUPet7rdjSmjG3YlcX05K18sGwbGQdzaFq3Jvf0P5uhCc1oXMe6zRrjU6IXkYHAv3DG\njJ2kqs8UmX8+8E+cwb+Hq+qsQvOeBQYBAcAC4C6tyPELD+91BhGpFQVXvF7pyoua4mXn5jP3px1M\nW5LKki0ZBAUI/Ts0YnhSc3q2bnD8QBbGVGMlJnoRCQReBvoDaUCyiMxR1TWFFtsKjALuLbJuD5wi\nEHGeSd8CvYBFpxu4TwoKYPatsH8bjP6s9AMbG7+z7vf9TFuSyofL0tifnUfL+mHcf1E7ruwSTVTt\nGm6HZ4xf8uWKPgnYoKqbAERkGnAp4E30qrrFM69oZScFQnEKQAsQDOw87ah99f0LsH4eDHwGmiVW\n2G5N2Tp4JI9PV23n/SWprEjdR0hgAANjGzM8qRndz6xvtWSMKYEvib4pkFrofRrgU3EGVf1BRBYC\nO3AS/UuqurbociIyDhgH0Lx5c182XbIt3zmDiHS4FM65pWy2aSrUT2mZvJ+8lTkrtpN1JI/WDcN5\neHAHrujclMhaIW6HZ0ylUa43Y0WkNdAeiPZMWiAiPVX1m8LLqepEYCJAQkLC6bffH9gJs0ZDZEsY\n8pINIlKJ7M/O5eMV25m2ZCurt+8nNDiAQR3P4JqkZnRtEWlX78acAl8S/TY4ZgSwaM80X1wOLFbV\nLAARmQd0B7456VqnoyDfGUQkOxNGfAihVm3Q36kqy7buY9qSrXy6ageHc/Np3ySCJy+NYUinpqc8\nspAxxuFLok8G2ohIK5wEPxy41sftbwXGisjTOE03vXB655SfhX9zBhG59N/QOLZcd2VOz75DOcxe\nvo33l2xl/c4saoUEclnnMxie2Jy46Dp29W5MGSkx0atqnojcAXyO073yTVVdLSJPACmqOkdEEoHZ\nOAN1XSIij6tqDDAL6Av8hHNj9jNV/aS8/hjWfw7fPAedr4fO15XbbsypK24wj/joOjxzRUcGx59B\neI3q8WiHMRVJKrJLuy8SEhI0JSWl9CvuS4VXz3NGYR+zwKlnY/xGcYN5XN65qQ3mYUwZEZGlqppQ\n3Lyqc/kUVh9ir4Tut1uS9xPFDeaR0MIG8zCmolWdRB8SBoP/4XYUBhvMwxh/U3USvXGVDeZhjP+y\nRG9Oy4kG87g6sRmtbDAPY/yCJXpTajaYhzGViyV64zMbzMOYyskSvTkpG8zDmMrPEr0plg3mYUzV\nYYneeNlgHsZUTZbojQ3mYUwVZ4m+Gvtk5Xbe+HazDeZhTBVnib6aeu/HrTw4+ydaNwznoUHtuaJL\nNPVsMA9jqiRL9NXQl+t28tBHP9GnbRSv35BgPWeMqeLsE17NrErbx+3vLifmjDq8dG0XS/LGVAP2\nKa9GUjMOceOUZOqHh/DGqARqWe13Y6oF+6RXE3sP5jBy8hJy85Vp45JoWNv6whtTXViirwayc/MZ\n+1YKaXsP885N59C6YbjbIRljKpA13VRxBQXKPTNWkvLbXv4xLJ6kVvXcDskYU8F8SvQiMlBEfhGR\nDSJyfzHzzxeRZSKSJyJXFZreR0RWFHpli8hlZfkHmJP729y1/OenHfzl4vYMjjvD7XCMMS4oselG\nRAKBl4H+QBqQLCJzVHVNocW2AqOAewuvq6oLgU6e7dQDNgDzyyRyU6LJ321m0rebGdWjJWN6tnI7\nHGOMS3xpo08CNqjqJgARmQZcCngTvapu8cwrOMl2rgLmqeqhU47W+Oyzn3fwxKdruLBDIx4e3MGe\ndDWmGvOl6aYpkFrofZpnWmkNB94vboaIjBORFBFJSU9PP4VNm8KW/pbBXdNW0KlZXf41vDOBVozM\nmGqtQm7GikgToCPweXHzVXWiqiaoakJUVFRFhFRlbUrPYszUFJrUCWXSDQnUDLGxWo2p7nxJ9NuA\nZoXeR3umlcYwYLaq5pZyPVMKu7OOMGpyMiLClNFJ1A+3ypPGGN8SfTLQRkRaiUgIThPMnFLu5xpO\n0GxjysbhnHxumprCrgPZTBqZQEsbmNsY41FiolfVPOAOnGaXtcAMVV0tIk+IyBAAEUkUkTRgKPCa\niKw+ur6ItMT5RvBV2YdvAPILlD9NW86qtH38a3hnujSPdDskY4wf8enJWFWdC8wtMu2RQr8n4zTp\nFLfuFk7t5q3xgary+CerWbBmJ48PiWFATGO3QzLG+Bl7MraSm/j1Jt764TfGnX8mI3u0dDscY4wf\nskRfic1ZuZ2n561jcFwT7h/Yzu1wjDF+yhJ9JbV40x7unbGSpFb1eG5ovA3cbYw5IUv0ldCvOw8w\n7q0UmtWrycTruxIabH3ljTEnZom+ktm1P5tRk5OpERzIlNFJ1A2zcV6NMSdnib4SyTqSx+gpyew9\nlMPkUYk0qxfmdkjGmErABh6pJHLzC7j93WWs+/0Ak0YmENu0jtshGWMqCbuirwRUlYdm/8xX69P5\n62Wx9Gnb0O2QjDGViCX6SuDFLzcwPSWVO/u2ZnhSc7fDMcZUMpbo/dyspWn8Y8F6rujSlLv7n+12\nOMaYSsgSvR/75td07v9gFee2rs8zV8TZ4CHGmFNiid5Prdm+n1vfWUbrhuG8MqIrIUH2T2WMOTWW\nPfzQ9n2HGT1lCeE1gpg8OpGI0GC3QzLGVGKW6P1M5uFcRk9O5tCRfCaPTqRJnZpuh2SMqeSsH70f\nyckr4Ja3l7IxPYupNybRvkmE2yEZY6oAS/R+QlW574NV/LBpD88Pjefc1g3cDskYU0VY042feG7+\nL8xevo17+p/NlV2LHcPFGGNOiSV6P/Dej1t5eeFGhic2446+rd0OxxhTxfiU6EVkoIj8IiIbROT+\nYuafLyLLRCRPRK4qMq+5iMwXkbUissYzhqzxWLhuFw999BO920bx1GWx1lfeGFPmSkz0IhIIvAxc\nBHQArhGRDkUW2wqMAt4rZhNvARNUtT2QBOw6nYCrkp/SMrn9vWV0OCOCl6/tQlCgfcEyxpQ9X27G\nJgEbVHUTgIhMAy4F1hxdwDMAOCJSUHhFzwkhSFUXeJbLKpuwK7/UjEOMnpJMZFgIb45KpFYNuy9u\njCkfvlxCNgVSC71P80zzxdnAPhH5UESWi8gEzzeEY4jIOBFJEZGU9PR0Hzddee07lMPIyUvIzS9g\n6o2JNKwd6nZIxpgqrLzbCoKAnsC9QCJwJk4TzzFUdaKqJqhqQlRUVDmH5K7s3HzGvpVCWsZhXr8h\ngdYNa7sdkjGmivMl0W8DmhV6H+2Z5os0YIWqblLVPOAjoEvpQqw6CgqUe2auJHnLXp4fFk9Sq3pu\nh2SMqQZ8SfTJQBsRaSUiIcBwYI6P208G6orI0cv0vhRq269unp63lv+s2sGDF7fjkvgz3A7HGFNN\nlJjoPVfidwCfA2uBGaq6WkSeEJEhACKSKCJpwFDgNRFZ7Vk3H6fZ5gsR+QkQ4PXy+VP825TvNvP6\nN5sZ2b0FY3ue6XY4xphqRFTV7RiOkZCQoCkpKW6HUaY++/l3bn13KRe0b8SrI7oSGGB95Y0xZUtE\nlqpqQnHzrON2OVv6217umrac+Oi6vDC8syV5Y0yFs0RfjjbvPsiYqck0rhPKGyMTqBlyXM9SY4wp\nd5boy8nurCOMmrwEEWHK6CTqh9dwOyRjTDVlib4cHM7J56apKfyemc2kkQm0alDL7ZCMMdWYPXdf\nxvILlD9NW86qtH28cl1XujSPdDskY0w1Z1f0ZUhVefyT1SxYs5NHB3dgYGxjt0MyxhhL9GVp4teb\neOuH3xjbsxWjzm3ldjjGGANYoi8zc1Zu5+l56xgU14QHLmrvdjjGGONlib4MLN60h3tnrCSpZT2e\nHxpPgPWVN8b4EUv0p+nXnQcY91YKzerVZOINXQkNtr7yxhj/Yon+NOzan82oycmEBAUyZXQSdcNC\n3A7JGGOOY4n+FGUdyWP0lGT2Hsph8qhEmtULczskY4wplvWjPwV5+QXc/u4y1v1+gEk3JNAxuo7b\nIRljzAnZFX0pqSoPffQzX61P56nLYunTrqHbIRljzElZoi+ll77cwLTkVO7o05prkpq7HY4xxpTI\nEn0pfLA0jecXrOeKzk2558Kz3Q7HGGN8YoneR9/+upv7PlhFj7Pq88yVcYhYX3ljTOVgid4Ha3fs\n55Z3lnJWVDivXt+VkCA7bMaYysOnjCUiA0XkFxHZICL3FzP/fBFZJiJ5InJVkXn5IrLC8/J1UHG/\nsSPzMKMnJxNeI4jJoxOJCA12OyRjjCmVErtXikgg8DLQH0gDkkVkjqquKbTYVmAUzkDgRR1W1U5l\nEGuF25+dy6g3k8k6ksfMW7pzRt2abodkjDGl5ks/+iRgg6puAhCRacClgDfRq+oWz7yCcojRFTl5\nBdz6zlI2pmcxeXQi7ZtEuB2SMcacEl+abpoCqYXep3mm+SpURFJEZLGIXFbcAiIyzrNMSnp6eik2\nXT5Ulfs/WMV3G/bwzJVx9GwT5XZIxhhzyirirmILVU0ArgX+KSJnFV1AVSeqaoKqJkRFuZ9Un5+/\nng+Xb+Pu/mdzVddot8MxxpjT4kui3wY0K/Q+2jPNJ6q6zfNzE7AI6FyK+Crcez9u5aWFGxie2Iw7\n+7Z2OxxjjDltviT6ZKCNiLQSkRBgOOBT7xkRiRSRGp7fGwDnUqht398sXLeLhz/+mV5nR/HkZbHW\nV94YUyWUmOhVNQ+4A/gcWAvMUNXVIvKEiAwBEJFEEUkDhgKvichqz+rtgRQRWQksBJ4p0lvHb/yU\nlsnt7y2jXePavHxdF4IDra+8MaZqEFV1O4ZjJCQkaEpKSoXuMzXjEJf/+3tqBAUw+7YeNIwIrdD9\nG2PM6RKRpZ77ocep9mWK9x3KYeTkJeTk5TNt3DmW5I0xVU61TvTZufmMfSuFtIzDvH1TEq0b1nY7\nJGOMKXPVNtEXFCj3zFxJ8pa9vHBNZ845s77bIRljTLmotnccn563lv+s2sEDF7VjSPwZbodjjDHl\nplom+infbeb1bzZzQ/cWjDv/TLfDMcaYclXtEv1nP//O45+u4YL2jXj0khjrK2+MqfKqVaJftnUv\nd01bTlx0XV68pjOBAZbkjTFVX7VJ9Ft2H2TM1BQaRYTyxsgEaoYEuh2SMcZUiGqR6PdkHWHk5CWo\nKlNvTKJBeA23QzLGmApT5btXHs7J56apKfyemc17Y7vRqkEtt0MyxpgKVaUTfX6B8qdpy1mZto9X\nrutK1xaRbodkjDEVrso23agqT3yymgVrdvLI4A4MjG3sdkjGGOOKKpvoX/9mE1N/+I0x57Vi9Lmt\n3A7HGGNcUyUT/Scrt/O3uesY1LEJD17c3u1wjDHGVVUu0f+4aQ/3zFhJYstInh8WT4D1lTfGVHNV\nKtFv2HWAsW+lEF2vJq/fkEBosPWVN8aYKpPodx3IZuSbyYQEBTJ1dBJ1w0LcDskYY/xCleleWSMo\nkHaNa3PXBW1oVi/M7XCMMcZv+HRFLyIDReQXEdkgIvcXM/98EVkmInkiclUx8yNEJE1EXiqLoItT\np2Ywb4xKJC66bnntwhhjKqUSE72IBAIvAxcBHYBrRKRDkcW2AqOA906wmSeBr089TGOMMafKlyv6\nJGCDqm5S1RxgGnBp4QVUdYuqrgIKiq4sIl2BRsD8MojXGGNMKfmS6JsCqYXep3mmlUhEAoDngXtL\nWG6ciKSISEp6erovmzbGGOOj8u51cxswV1XTTraQqk5U1QRVTYiKiirnkIwxpnrxpdfNNqBZoffR\nnmm+6A70FJHbgHAgRESyVPW4G7rGGGPKhy+JPhloIyKtcBL8cOBaXzauqtcd/V1ERgEJluSNMaZi\nldh0o6p5wB3A58BaYIaqrhaRJ0RkCICIJIpIGjAUeE1EVpdn0MYYY3wnqup2DMdISEjQlJQUt8Mw\nxphKRUSWqmpCsfP8LdGLSDrw22lsogGwu4zCKUsWV+lYXKVjcZVOVYyrhaoW25vF7xL96RKRlBOd\n1dxkcZWOxVU6FlfpVLe4qkxRM2OMMcWzRG+MMVVcVUz0E90O4AQsrtKxuErH4iqdahVXlWujN8YY\nc6yqeEVvjDGmEEv0xhhTxVXKRO/DQCg1RGS6Z/6PItLST+IaJSLpIrLC8xpTQXG9KSK7ROTnE8wX\nEXnBE/cqEeniJ3H1FpHMQsfrkQqKq5mILBSRNSKyWkTuKmaZCj9mPsZV4cdMREJFZImIrPTE9Xgx\ny1T4Z9LHuFz5THr2HSgiy0Xk02Lmle3xUtVK9QICgY3AmUAIsBLoUGSZ24BXPb8PB6b7SVyjgJdc\nOGbnA12An08w/2JgHiBAN+BHP4mrN/CpC8erCdDF83ttYH0x/5YVfsx8jKvCj5nnGIR7fg8GfgS6\nFVnGjc+kL3G58pn07PtunMGajvv3KuvjVRmv6EscCMXzfqrn91lAPxERP4jLFar6NZBxkkUuBd5S\nx2Kgrog08YO4XKGqO1R1mef3Azg1noqOwVDhx8zHuCqc5xhked4Ge15Fe3lU+GfSx7hcISLRwCBg\n0gkWKdPjVRkTvS8DoXiXUacoWyZQ3w/iArjS81V/log0K2a+G055cJkK0N3z1XueiMRU9M49X5k7\n41wNFubqMTtJXODCMfM0Q6wAdgELVPWEx6sCP5O+xAXufCb/CfyZYkbl8yjT41UZE31l9gnQUlXj\ngAX8ccY2xVuGU78jHngR+Kgidy4i4cAHwP+o6v6K3PfJlBCXK8dMVfNVtRPOeBVJIhJbEfstiQ9x\nVfhnUkQGA7tUdWl57+uoypjofRkIxbuMiAQBdYA9bselqntU9Yjn7SSgaznH5KvTGVym3Kjq/qNf\nvVV1LhAsIg0qYt8iEoyTTN9V1Q+LWcSVY1ZSXG4eM88+9wELgYFFZrnxmSwxLpc+k+cCQ0RkC04T\nb18ReafIMmV6vCpjovcOhCIiITg3KuYUWWYOMNLz+1XAl+q5q+FmXEXacIfgtLH6gznADZ6eJN2A\nTFXd4XZQItL4aLukiCTh/H8t9+Tg2ecbwFpV/ccJFqvwY+ZLXG4cMxGJEpG6nt9rAv2BdUUWq/DP\npC9xufGZVNUHVDVaVVvi5IkvVXVEkcXK9Hj5MsKUX1HVPBE5OhBKIPCmegZCAVJUdQ7Oh+FtEdmA\nc7NvuJ/E9SdxBmvJ88Q1qrzjAhCR93F6YzQQZ4CYR3FuTKGqrwJzcXqRbAAOAaP9JK6rgFtFJA84\nDAyvgBM2OFdc1wM/edp3AR4EmheKzY1j5ktcbhyzJsBUEQnEObHMUNVP3f5M+hiXK5/J4pTn8bIS\nCMYYU8VVxqYbY4wxpWCJ3hhjqjhL9MYYU8VZojfGmCrOEr0xxlRxluiNMaaKs0RvjDFV3P8Df32t\nMOG+eBQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1bvhM2G22vi"
      },
      "source": [
        "## 3) Test on two classes\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUHC890px71N",
        "outputId": "59cdfa09-02ea-4c72-b305-e931cf1157dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\"\"\"Preparation of a two class dataset\"\"\"\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# prepare the train data \n",
        "\n",
        "train_images_sorted = [[] for k in range(10)]\n",
        "train_labels_sorted = [[] for k in range(10)]\n",
        "\n",
        "for k in range(len(train_images)):\n",
        "  nb_class = train_labels[k][0]\n",
        "  train_images_sorted[nb_class].append(train_images[k])\n",
        "  train_labels_sorted[nb_class].append(train_labels[k][0])\n",
        "\n",
        "\n",
        "\n",
        "train_images_airplane = train_images_sorted[0]\n",
        "train_labels_airplane = train_labels_sorted[0]\n",
        "train_images_horse = train_images_sorted[5]\n",
        "train_labels_horse = train_labels_sorted[5]\n",
        "\n",
        "#replace the name of label 7 by 1\n",
        "for k in range(len(train_labels_horse)):\n",
        "  train_labels_horse[k]=1\n",
        "\n",
        "train_images_2=np.array(train_images_airplane+train_images_horse)\n",
        "train_labels_2=np.array(train_labels_airplane+train_labels_horse)\n",
        "\n",
        "\n",
        "# prepare the test data\n",
        "\n",
        "test_images_sorted = [[] for k in range(10)]\n",
        "test_labels_sorted = [[] for k in range(10)]\n",
        "\n",
        "for k in range(len(test_images)):\n",
        "  nb_class = test_labels[k][0]\n",
        "  test_images_sorted[nb_class].append(test_images[k])\n",
        "  test_labels_sorted[nb_class].append(test_labels[k][0])\n",
        "\n",
        "\n",
        "test_images_airplane = test_images_sorted[0]\n",
        "test_labels_airplane = test_labels_sorted[0]\n",
        "test_images_horse = test_images_sorted[5]\n",
        "test_labels_horse = test_labels_sorted[5]\n",
        "\n",
        "#replace the name of label 7 by 1\n",
        "for k in range(len(test_labels_horse)):\n",
        "  test_labels_horse[k]=1\n",
        "\n",
        "\n",
        "test_images_2=np.array(test_images_airplane+test_images_horse)\n",
        "test_labels_2=np.array(test_labels_airplane+test_labels_horse)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Test of the CNN with 2 outputs\"\"\"\n",
        "\n",
        "CNNetwork2=model(0.003,\"CNN\")\n",
        "filters_list=CNNetwork2.create_filters(5,3)\n",
        "layer1=convolution_layer(filters_list)\n",
        "layer2=relu_layer_conv(10,5)\n",
        "layer3=pooling_layer(10,5,[5,5])\n",
        "layer4=convert_layer()\n",
        "layer5=net_layer(180,2,10)\n",
        "layer6=relu_layer_mlp(2,2,10)\n",
        "\n",
        "CNNetwork2.add_layer(layer1)\n",
        "CNNetwork2.add_layer(layer2)\n",
        "CNNetwork2.add_layer(layer3)\n",
        "CNNetwork2.add_layer(layer4)\n",
        "CNNetwork2.add_layer(layer5)\n",
        "CNNetwork2.add_layer(layer6)\n",
        "\n",
        "#create the input for the test set \n",
        "test_list2,test_labels_list2=CNNetwork2.create_input(test_images_2, test_labels_2, len(test_labels_2),True)\n",
        "\n",
        "start_time=time.time()\n",
        "\n",
        "\n",
        "#iterate over the epoch\n",
        "for epoch in range (3):\n",
        "  print(\"\\n-------- Epoch:\"+str(epoch)+\"--------\\n\")\n",
        "  \n",
        "  #create the batch list for the training\n",
        "  batch_list2,batch_labels_list2=CNNetwork2.create_input(train_images_2, train_labels_2, 10,True)\n",
        "  \n",
        "  #train for each batch\n",
        "  counter=0\n",
        "  accuracy_list=[]\n",
        "  batch_number_list=[]\n",
        "  for b,l in zip(batch_list2,batch_labels_list2):\n",
        "    # because the process can be long, we print  and  record every 500 batch the \n",
        "    #time  and the accuracy on the all the batches that went into the network for now\n",
        "    \n",
        "    if counter%100==0:\n",
        "      curr_accuracy=CNNetwork2.correct_match/((counter+1)*10)\n",
        "      print(\"Execution time :\"+ str( (time.time() - start_time))+\" batch: \"+str(counter))\n",
        "      print(\"Network accuracy\", curr_accuracy)\n",
        "      batch_number_list.append(counter)\n",
        "      accuracy_list.append(curr_accuracy)\n",
        "\n",
        "    counter+=1\n",
        "\n",
        "    #train the model\n",
        "    CNNetwork2.fit(b,l)\n",
        "\n",
        "  \n",
        "  \n",
        "  print(\"Execution time: %s secondes ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "  print(\"accuracy on train_set\",CNNetwork2.correct_match/len(train_labels_2))\n",
        "  CNNetwork2.correct_match=0\n",
        "  test_accuracy,precision,recall=CNNetwork2.prediction(test_list2[0][:1000],test_labels_list2[0][:1000],2)\n",
        "  print(\"accuracy on test_set\", test_accuracy)\n",
        "  CNNetwork2.correct_match=0\n",
        "  print(\"Execution time: %s secondes ---\" % (time.time() - start_time))\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------- Epoch:0--------\n",
            "\n",
            "Execution time :0.3074190616607666 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :50.62791299819946 batch: 100\n",
            "Network accuracy 0.498019801980198\n",
            "Execution time :101.11337971687317 batch: 200\n",
            "Network accuracy 0.49502487562189057\n",
            "Execution time :151.46150255203247 batch: 300\n",
            "Network accuracy 0.5003322259136213\n",
            "Execution time :201.70168042182922 batch: 400\n",
            "Network accuracy 0.5054862842892768\n",
            "Execution time :252.41843342781067 batch: 500\n",
            "Network accuracy 0.4994011976047904\n",
            "Execution time :302.656152009964 batch: 600\n",
            "Network accuracy 0.4963394342762063\n",
            "Execution time :353.31227946281433 batch: 700\n",
            "Network accuracy 0.49586305278174037\n",
            "Execution time :403.3653964996338 batch: 800\n",
            "Network accuracy 0.5\n",
            "Execution time :453.5992875099182 batch: 900\n",
            "Network accuracy 0.5011098779134295\n",
            "Execution time: 503.6750690937042 secondes ---\n",
            "accuracy on train_set 0.504\n",
            "  Class: 0 Correct match:479 Number of elements:483 Forecast as i:990\n",
            "  Class: 1 Correct match:6 Number of elements:517 Forecast as i:10\n",
            " \n",
            "\n",
            " precisions for all classes: [0.48383838383838385, 0.6]\n",
            "  recall for all classes:[0.9917184265010351, 0.01160541586073501]\n",
            "  Accuracy0.485\n",
            "accuracy on test_set 0.485\n",
            "Execution time: 551.429589509964 secondes ---\n",
            "\n",
            "-------- Epoch:1--------\n",
            "\n",
            "Execution time :551.6799397468567 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :602.3366222381592 batch: 100\n",
            "Network accuracy 0.48415841584158414\n",
            "Execution time :653.6629209518433 batch: 200\n",
            "Network accuracy 0.4945273631840796\n",
            "Execution time :704.2765474319458 batch: 300\n",
            "Network accuracy 0.501328903654485\n",
            "Execution time :754.8325300216675 batch: 400\n",
            "Network accuracy 0.5124688279301746\n",
            "Execution time :805.5593268871307 batch: 500\n",
            "Network accuracy 0.5127744510978044\n",
            "Execution time :855.7246463298798 batch: 600\n",
            "Network accuracy 0.5094841930116473\n",
            "Execution time :906.1401226520538 batch: 700\n",
            "Network accuracy 0.5069900142653352\n",
            "Execution time :956.5582146644592 batch: 800\n",
            "Network accuracy 0.5081148564294632\n",
            "Execution time :1006.7842817306519 batch: 900\n",
            "Network accuracy 0.5055493895671476\n",
            "Execution time: 1057.2115659713745 secondes ---\n",
            "accuracy on train_set 0.5041\n",
            "  Class: 0 Correct match:479 Number of elements:483 Forecast as i:990\n",
            "  Class: 1 Correct match:6 Number of elements:517 Forecast as i:10\n",
            " \n",
            "\n",
            " precisions for all classes: [0.48383838383838385, 0.6]\n",
            "  recall for all classes:[0.9917184265010351, 0.01160541586073501]\n",
            "  Accuracy0.485\n",
            "accuracy on test_set 0.485\n",
            "Execution time: 1104.9822385311127 secondes ---\n",
            "\n",
            "-------- Epoch:2--------\n",
            "\n",
            "Execution time :1105.1789727210999 batch: 0\n",
            "Network accuracy 0.0\n",
            "Execution time :1155.2198390960693 batch: 100\n",
            "Network accuracy 0.498019801980198\n",
            "Execution time :1205.5302066802979 batch: 200\n",
            "Network accuracy 0.5004975124378109\n",
            "Execution time :1255.8852045536041 batch: 300\n",
            "Network accuracy 0.4963455149501661\n",
            "Execution time :1305.9864966869354 batch: 400\n",
            "Network accuracy 0.5002493765586035\n",
            "Execution time :1356.3539009094238 batch: 500\n",
            "Network accuracy 0.4992015968063872\n",
            "Execution time :1406.6757442951202 batch: 600\n",
            "Network accuracy 0.49983361064891846\n",
            "Execution time :1456.698346376419 batch: 700\n",
            "Network accuracy 0.5014265335235378\n",
            "Execution time :1507.1128075122833 batch: 800\n",
            "Network accuracy 0.5046192259675406\n",
            "Execution time :1557.5928118228912 batch: 900\n",
            "Network accuracy 0.5048834628190899\n",
            "Execution time: 1608.0299172401428 secondes ---\n",
            "accuracy on train_set 0.5046\n",
            "  Class: 0 Correct match:479 Number of elements:483 Forecast as i:990\n",
            "  Class: 1 Correct match:6 Number of elements:517 Forecast as i:10\n",
            " \n",
            "\n",
            " precisions for all classes: [0.48383838383838385, 0.6]\n",
            "  recall for all classes:[0.9917184265010351, 0.01160541586073501]\n",
            "  Accuracy0.485\n",
            "accuracy on test_set 0.485\n",
            "Execution time: 1655.419783115387 secondes ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG81cLHH9mlq"
      },
      "source": [
        "#Conclusion\n",
        "#Results:\n",
        "I Neural Network alone with 10 classes. <br>\n",
        "We had good results when we trained the neural network alone. We reached 23% of accuracy when trained on the 10 classes but it seems to depend a lot of the seed value and it does not work with a shuffle. The recall and the precision rates shows that MLP is not adequate for some classes.   <br><br>\n",
        "\n",
        "II Whole CNN with 10 classes.<br>\n",
        "The CNN performed better than random but was less efficient than the neural network alone. We reached at most 20% of accuracy. In addition, recall and precision calculations revealed that some classes are never recognized while others are in most of the cases.<br><br>\n",
        "\n",
        "III Whole CNN with 2 classes.<br>\n",
        "We reduced the dataset to two classes, for instance plane and horses. However, after many tests with changing learning rates we didn’t get any improvement on the accuracy. Indeed, it remained very close to 0.5, even after a few epochs.\n",
        "#Interpretation:\n",
        "The test phase allowed us to understand the importance of the learning rate definition. The whole CNN with 10 classes seemed to work better with a learning rate of 0.003, while the neural network alone worked well with a learning rate of 0.1. We tried many different rates for the CNN with 2 classes, but none of them gave good results (we even tried to put different learning rates for the different layers!).\n",
        "At the beginning we didn’t shuffle the dataset between epochs, but knowing that some classes were never recognized (cf II), we finally thought it would be relevant to do so. However, the neural network didn’t train well with the shuffle, while the feature learning step performed as well as before.\n",
        "While the results are not very satisfying, we are completely satisfied about our work. Our main goal was to understand the deep functioning of a CNN and to implement it from scratch and so we did. We think the results could be improved by increasing the number of filters used and the number of convolution layers."
      ]
    }
  ]
}